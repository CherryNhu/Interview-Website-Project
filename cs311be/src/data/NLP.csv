STT,Câu hỏi,Trả lời
1,Xử lý Ngôn ngữ Tự nhiên (NLP) là gì?,"Xử lý Ngôn ngữ Tự nhiên (NLP) là một lĩnh vực của trí tuệ nhân tạo tập trung vào việc cho phép máy tính hiểu, diễn giải và tạo ra ngôn ngữ con người một cách tự nhiên. Nó liên quan đến các kỹ thuật để xử lý văn bản, giọng nói và dữ liệu ngôn ngữ khác, bao gồm các nhiệm vụ như phân tích cảm xúc, dịch máy, nhận dạng giọng nói và tạo văn bản."
2,Các thành phần chính của pipeline NLP là gì?,"Pipeline NLP bao gồm các bước: Tiền xử lý văn bản (loại bỏ nhiễu, chuẩn hóa), Tokenization (phân tách văn bản thành từ hoặc cụm từ), Lemmatization/Stemming (chuẩn hóa từ về dạng gốc), Xóa từ dừng (loại bỏ từ phổ biến như ""là"", ""của""), Nhúng từ (biểu diễn từ thành vector), Phân tích cú pháp (phân tích cấu trúc câu), và Mô hình hóa (áp dụng mô hình học máy hoặc học sâu để xử lý nhiệm vụ cụ thể)."
3,Tokenization là gì trong NLP?,"Tokenization là quá trình chia văn bản thành các đơn vị nhỏ hơn, như từ, cụm từ hoặc ký hiệu, được gọi là token. Đây là bước đầu tiên trong pipeline NLP, giúp chuẩn bị dữ liệu cho các nhiệm vụ phân tích hoặc mô hình hóa tiếp theo."
4,Sự khác biệt giữa stemming và lemmatization là gì?,"Stemming cắt bỏ hậu tố để đưa từ về dạng gốc (ví dụ: ""running"" thành ""run""), thường đơn giản và nhanh nhưng có thể không chính xác. Lemmatization phân tích từ dựa trên ngữ cảnh và từ điển để trả về dạng gốc chính xác (ví dụ: ""better"" thành ""good""), chính xác hơn nhưng tốn tài nguyên hơn."
5,Nhúng từ (Word Embeddings) là gì?,"Nhúng từ là kỹ thuật biểu diễn từ dưới dạng vector số trong không gian nhiều chiều, nắm bắt ý nghĩa ngữ nghĩa và mối quan hệ giữa các từ. Ví dụ: Word2Vec, GloVe, và FastText. Các vector này được sử dụng trong các mô hình NLP để cải thiện hiệu suất nhiệm vụ như phân loại văn bản hoặc dịch máy."
6,Word2Vec hoạt động như thế nào?,"Word2Vec là mô hình nhúng từ sử dụng mạng nơ-ron để học biểu diễn vector của từ dựa trên ngữ cảnh. Có hai kiến trúc: CBOW (Continuous Bag of Words) dự đoán từ mục tiêu từ ngữ cảnh xung quanh, và Skip-gram dự đoán ngữ cảnh từ từ mục tiêu. Nó tối ưu hóa để nắm bắt mối quan hệ ngữ nghĩa."
7,Sự khác biệt giữa mô hình Bag of Words (BoW) và TF-IDF là gì?,"Bag of Words (BoW) biểu diễn văn bản dưới dạng tập hợp từ không quan tâm thứ tự, chỉ đếm tần suất từ. TF-IDF (Term Frequency-Inverse Document Frequency) cũng đếm tần suất nhưng điều chỉnh trọng số dựa trên mức độ hiếm của từ trong tập tài liệu, làm nổi bật các từ quan trọng hơn."
8,Mô hình Transformer là gì?,"Transformer là một kiến trúc mạng nơ-ron dựa trên cơ chế chú ý (attention mechanism), được giới thiệu trong bài báo ""Attention is All You Need"". Nó hiệu quả trong việc nắm bắt phụ thuộc dài hạn trong chuỗi, được sử dụng rộng rãi trong các nhiệm vụ NLP như dịch máy, tóm tắt văn bản và tạo văn bản."
9,Cơ chế chú ý (Attention Mechanism) là gì?,"Cơ chế chú ý cho phép mô hình tập trung vào các phần quan trọng của dữ liệu đầu vào khi xử lý một nhiệm vụ. Nó gán trọng số cho các thành phần đầu vào dựa trên mức độ liên quan, giúp cải thiện hiệu suất trong các nhiệm vụ như dịch máy hoặc phân tích cảm xúc."
10,BERT là gì và nó hoạt động như thế nào?,"BERT (Bidirectional Encoder Representations from Transformers) là mô hình Transformer hai chiều học biểu diễn từ bằng cách xem xét ngữ cảnh từ cả hai phía (trái và phải). Nó được huấn luyện trước trên nhiệm vụ dự đoán từ bị che (Masked Language Model) và dự đoán câu tiếp theo, sau đó được tinh chỉnh cho các nhiệm vụ NLP cụ thể."
11,"Sự khác biệt giữa RNN, LSTM và GRU là gì?","RNN (Recurrent Neural Network) xử lý chuỗi tuần tự nhưng dễ gặp vấn đề gradient biến mất. LSTM (Long Short-Term Memory) cải tiến bằng cách sử dụng cổng (gate) để kiểm soát dòng thông tin, giữ được phụ thuộc dài hạn. GRU (Gated Recurrent Unit) là phiên bản đơn giản hóa của LSTM, nhanh hơn nhưng vẫn hiệu quả trong việc nắm bắt phụ thuộc dài."
12,Phân tích cảm xúc (Sentiment Analysis) là gì?,"Phân tích cảm xúc là nhiệm vụ NLP xác định cảm xúc hoặc ý kiến trong văn bản, ví dụ: tích cực, tiêu cực hoặc trung lập. Nó thường được sử dụng trong phân tích đánh giá sản phẩm, phản hồi khách hàng hoặc mạng xã hội."
13,Nhận dạng thực thể có tên (NER) là gì?,"Nhận dạng thực thể có tên (NER) là nhiệm vụ NLP xác định và phân loại các thực thể như tên người, tổ chức, địa điểm trong văn bản. Ví dụ: Trong câu ""Apple ra mắt iPhone mới tại California"", NER sẽ nhận diện ""Apple"" (tổ chức), ""iPhone"" (sản phẩm), ""California"" (địa điểm)."
14,Dịch máy (Machine Translation) là gì?,"Dịch máy là nhiệm vụ NLP tự động dịch văn bản từ ngôn ngữ này sang ngôn ngữ khác, ví dụ: từ tiếng Anh sang tiếng Việt. Các mô hình như Transformer và các dịch vụ như Google Translate sử dụng kỹ thuật này."
15,Tóm tắt văn bản (Text Summarization) là gì?,"Tóm tắt văn bản là quá trình tạo ra bản tóm tắt ngắn gọn, giữ lại ý chính của văn bản dài. Có hai loại: tóm tắt trích xuất (extractive) chọn câu quan trọng, và tóm tắt trừu tượng (abstractive) tạo câu mới dựa trên nội dung."
16,Các thách thức trong NLP là gì?,"Các thách thức trong NLP bao gồm: Đa nghĩa ngôn ngữ (từ có nhiều nghĩa), thiếu dữ liệu huấn luyện chất lượng, xử lý ngôn ngữ ít tài nguyên, hiểu ngữ cảnh phức tạp, và đảm bảo tính công bằng, không thiên vị trong mô hình."
17,Mô hình ngôn ngữ lớn (LLM) là gì?,"Mô hình ngôn ngữ lớn (Large Language Model) là mô hình học sâu được huấn luyện trên tập dữ liệu văn bản khổng lồ để tạo hoặc hiểu ngôn ngữ tự nhiên. Ví dụ: GPT-3, BERT, LLaMA. Chúng được sử dụng trong các nhiệm vụ như trò chuyện, tạo văn bản và trả lời câu hỏi."
18,Fine-tuning trong NLP là gì?,"Fine-tuning là quá trình tinh chỉnh một mô hình đã được huấn luyện trước (pre-trained) trên tập dữ liệu cụ thể của một nhiệm vụ NLP, như phân loại văn bản hoặc dịch máy, để cải thiện hiệu suất trên nhiệm vụ đó."
19,Pre-training trong NLP là gì?,Pre-training là quá trình huấn luyện mô hình trên tập dữ liệu lớn và tổng quát (như Wikipedia) để học các đặc trưng ngôn ngữ cơ bản trước khi tinh chỉnh cho nhiệm vụ cụ thể. Ví dụ: BERT được pre-train trên nhiệm vụ dự đoán từ bị che.
20,Sự khác biệt giữa mô hình generative và discriminative trong NLP là gì?,"Mô hình generative (tạo sinh) học phân phối xác suất chung của dữ liệu và nhãn, dùng để tạo dữ liệu mới (ví dụ: GPT). Mô hình discriminative học ranh giới giữa các lớp, dùng để phân loại (ví dụ: BERT cho phân loại văn bản)."
21,N-gram là gì?,"N-gram là chuỗi gồm n từ liên tiếp trong văn bản, được sử dụng để mô hình hóa ngôn ngữ. Ví dụ: Trong câu ""Tôi học AI"", bigram (n=2) là ""Tôi học"", ""học AI"". Chúng hữu ích trong các mô hình ngôn ngữ đơn giản."
22,TF-IDF được sử dụng như thế nào trong NLP?,"TF-IDF được sử dụng để đánh giá tầm quan trọng của từ trong tài liệu so với tập tài liệu. Nó kết hợp tần suất từ (Term Frequency) và nghịch đảo tần suất tài liệu (Inverse Document Frequency) để gán trọng số, giúp xác định từ khóa quan trọng."
23,Bag of Words (BoW) có nhược điểm gì?,"Nhược điểm của BoW: Không nắm bắt được thứ tự từ, mất ngữ cảnh và ý nghĩa ngữ pháp, không phân biệt được từ đồng nghĩa hoặc đa nghĩa, và tạo ra vector thưa thớt, gây tốn tài nguyên tính toán."
24,Stop words là gì?,"Stop words là các từ phổ biến (như ""là"", ""của"", ""và"") mang ít ý nghĩa trong phân tích văn bản, thường được loại bỏ trong tiền xử lý NLP để giảm nhiễu và tập trung vào từ quan trọng."
25,Part-of-Speech (POS) Tagging là gì?,"POS Tagging là quá trình gán nhãn từ loại (danh từ, động từ, tính từ, v.v.) cho từng từ trong câu. Nó giúp phân tích cấu trúc ngữ pháp và hỗ trợ các nhiệm vụ như NER hoặc phân tích cảm xúc."
26,Dependency Parsing là gì?,"Dependency Parsing là quá trình phân tích cấu trúc ngữ pháp của câu bằng cách xác định mối quan hệ phụ thuộc giữa các từ (ví dụ: từ nào là chủ ngữ, từ nào là tân ngữ). Nó hữu ích trong việc hiểu cấu trúc câu phức tạp."
27,Word Sense Disambiguation (WSD) là gì?,"WSD là nhiệm vụ xác định nghĩa đúng của từ dựa trên ngữ cảnh, vì một từ có thể có nhiều nghĩa (ví dụ: ""bank"" có thể là ""ngân hàng"" hoặc ""bờ sông""). Nó quan trọng trong dịch máy và tìm kiếm thông tin."
28,Named Entity Recognition (NER) được sử dụng như thế nào?,"NER được sử dụng để nhận diện và phân loại thực thể có tên (như người, tổ chức, địa điểm) trong văn bản. Ứng dụng bao gồm tìm kiếm thông tin, chatbot, và phân tích dữ liệu văn bản."
29,Các kỹ thuật tiền xử lý văn bản trong NLP là gì?,"Các kỹ thuật tiền xử lý bao gồm: Tokenization, xóa stop words, stemming/lemmatization, chuẩn hóa văn bản (chuyển thành chữ thường, xóa dấu câu), xử lý ký tự đặc biệt, và nhúng từ."
30,Sự khác biệt giữa supervised và unsupervised learning trong NLP là gì?,Supervised learning sử dụng dữ liệu có nhãn để huấn luyện mô hình (ví dụ: phân loại cảm xúc). Unsupervised learning tìm mẫu trong dữ liệu không nhãn (ví dụ: phân cụm văn bản hoặc nhúng từ).
31,BLEU score là gì?,"BLEU (Bilingual Evaluation Understudy) là một độ đo để đánh giá chất lượng bản dịch máy bằng cách so sánh bản dịch với bản dịch tham chiếu, dựa trên sự trùng khớp n-gram. Nó thường được sử dụng trong dịch máy."
32,ROUGE score là gì?,"ROUGE (Recall-Oriented Understudy for Gisting Evaluation) là độ đo đánh giá chất lượng tóm tắt văn bản hoặc dịch máy bằng cách so sánh văn bản tạo ra với văn bản tham chiếu, dựa trên sự trùng khớp từ, cụm từ hoặc n-gram."
33,Perplexity trong mô hình ngôn ngữ là gì?,Perplexity đo lường độ không chắc chắn của mô hình ngôn ngữ khi dự đoán từ tiếp theo. Giá trị perplexity thấp hơn cho thấy mô hình dự đoán tốt hơn. Nó thường được sử dụng để đánh giá mô hình ngôn ngữ.
34,Các mô hình ngôn ngữ dựa trên Transformer phổ biến là gì?,"Các mô hình phổ biến bao gồm BERT, GPT, T5, RoBERTa, và XLNet. Chúng được sử dụng trong các nhiệm vụ như tạo văn bản, phân loại văn bản, dịch máy, và trả lời câu hỏi."
35,Chatbot hoạt động như thế nào trong NLP?,"Chatbot sử dụng NLP để hiểu đầu vào người dùng, xử lý ngữ cảnh và tạo phản hồi. Chúng thường dựa trên mô hình ngôn ngữ (như Transformer), kết hợp với các kỹ thuật như nhận dạng ý định, NER và quản lý hội thoại."
36,Các kỹ thuật để xử lý ngôn ngữ ít tài nguyên là gì?,"Các kỹ thuật bao gồm: Transfer learning (sử dụng mô hình pre-trained), tăng cường dữ liệu (data augmentation), sử dụng nhúng đa ngôn ngữ, và thu thập dữ liệu từ các nguồn như mạng xã hội."
37,Sự khác biệt giữa mô hình ngôn ngữ một chiều và hai chiều là gì?,"Mô hình một chiều (như GPT) dự đoán từ dựa trên ngữ cảnh một phía (trái hoặc phải). Mô hình hai chiều (như BERT) xem xét ngữ cảnh từ cả hai phía, phù hợp hơn cho các nhiệm vụ như phân loại hoặc NER."
38,Language Model Prompting là gì?,"Prompting là kỹ thuật cung cấp đầu vào (prompt) cho mô hình ngôn ngữ để định hướng phản hồi. Ví dụ: Hỏi ""Thủ đô của Việt Nam là gì?"" để nhận câu trả lời chính xác từ mô hình như GPT."
39,Các thách thức trong dịch máy là gì?,"Các thách thức bao gồm: Xử lý ngôn ngữ đa nghĩa, bảo tồn ngữ cảnh văn hóa, xử lý ngôn ngữ hiếm, và đảm bảo bản dịch mạch lạc và tự nhiên."
40,Các ứng dụng của NLP trong đời thực là gì?,"Ứng dụng bao gồm: Chatbot, trợ lý ảo (Siri, Alexa), dịch máy (Google Translate), phân tích cảm xúc, tóm tắt văn bản, tìm kiếm thông tin, và phân tích dữ liệu mạng xã hội."
41,Sự khác biệt giữa word embeddings và character embeddings là gì?,"Word embeddings biểu diễn toàn bộ từ dưới dạng vector (ví dụ: Word2Vec). Character embeddings biểu diễn từng ký tự, hữu ích cho ngôn ngữ có từ vựng lớn hoặc lỗi chính tả, nhưng phức tạp hơn."
42,Text Classification trong NLP là gì?,"Phân loại văn bản là nhiệm vụ gán nhãn cho văn bản dựa trên nội dung, như phân loại cảm xúc (tích cực/tiêu cực) hoặc phân loại chủ đề (thể thao/chính trị). Nó thường sử dụng các mô hình như BERT hoặc CNN."
43,Các kỹ thuật để cải thiện hiệu suất mô hình NLP là gì?,"Các kỹ thuật bao gồm: Tăng dữ liệu huấn luyện, fine-tuning mô hình pre-trained, sử dụng nhúng tốt hơn, chính quy hóa (regularization), và tối ưu hóa siêu tham số."
44,Text Generation trong NLP là gì?,"Tạo văn bản là quá trình sử dụng mô hình NLP (như GPT) để tạo văn bản mạch lạc, tự nhiên dựa trên đầu vào hoặc ngữ cảnh. Ứng dụng bao gồm viết bài tự động, chatbot và sáng tác nội dung."
45,Các công cụ và thư viện NLP phổ biến là gì?,"Các công cụ và thư viện bao gồm: NLTK, SpaCy, Hugging Face Transformers, Stanford NLP, AllenNLP, và Gensim. Chúng hỗ trợ từ tiền xử lý đến huấn luyện mô hình."
46,Vector Space Model trong NLP là gì?,"Vector Space Model biểu diễn văn bản dưới dạng vector trong không gian nhiều chiều, cho phép đo lường sự giống nhau giữa các văn bản (ví dụ: cosine similarity). Nó được sử dụng trong tìm kiếm thông tin và phân loại văn bản."
47,Các kỹ thuật để xử lý dữ liệu văn bản không cân bằng là gì?,"Các kỹ thuật bao gồm: Tái lấy mẫu (oversampling/undersampling), sử dụng trọng số lớp, tăng cường dữ liệu, và sử dụng thuật toán như SMOTE để tạo dữ liệu tổng hợp."
48,Các vấn đề đạo đức trong NLP là gì?,"Các vấn đề bao gồm: Thiên vị trong mô hình (bias), quyền riêng tư dữ liệu, lạm dụng tạo nội dung giả (deepfake text), và đảm bảo tính công bằng trong ứng dụng NLP."
49,Tương lai của NLP là gì?,"Tương lai của NLP bao gồm: Mô hình ngôn ngữ lớn hơn, hiệu quả hơn; tích hợp đa phương thức (văn bản, hình ảnh, âm thanh); cải thiện ngôn ngữ ít tài nguyên; và tập trung vào tính bền vững, đạo đức trong AI."
