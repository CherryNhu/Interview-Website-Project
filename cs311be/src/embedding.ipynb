{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed39423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Using cached numpy-2.3.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Using cached pandas-2.3.2-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "Using cached numpy-2.3.3-cp311-cp311-win_amd64.whl (13.1 MB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
      "\n",
      "   ---------------------------------------- 0/6 [pytz]\n",
      "   ---------------------------------------- 0/6 [pytz]\n",
      "   ---------------------------------------- 0/6 [pytz]\n",
      "   ------ --------------------------------- 1/6 [tzdata]\n",
      "   ------ --------------------------------- 1/6 [tzdata]\n",
      "   ------ --------------------------------- 1/6 [tzdata]\n",
      "   ------ --------------------------------- 1/6 [tzdata]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------- ------------------- 3/6 [numpy]\n",
      "   -------------------------- ------------- 4/6 [python-dateutil]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   --------------------------------- ------ 5/6 [pandas]\n",
      "   ---------------------------------------- 6/6 [pandas]\n",
      "\n",
      "Successfully installed numpy-2.3.3 pandas-2.3.2 python-dateutil-2.9.0.post0 pytz-2025.2 six-1.17.0 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e3b7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "\n",
      "   ---------------------------------------- 2/2 [dotenv]\n",
      "\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed75f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore path: D:\\CODE\\dsc2025\\dsc2025API\\src\\chroma_db_master_program\n",
      "Path exists: True\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import chromadb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get vectorstore path from environment\n",
    "vectorstore_path = os.getenv(\"VECTORSTORE_PATH\")\n",
    "if not vectorstore_path:\n",
    "    vectorstore_path = \"../../chroma_db_eachfileisanode\"  # Default path\n",
    "\n",
    "print(f\"Vectorstore path: {vectorstore_path}\")\n",
    "print(f\"Path exists: {os.path.exists(vectorstore_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa934d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total collections found: 3\n",
      "\n",
      "Collections:\n",
      "1. question_collection\n",
      "2. QA_collection\n",
      "3. question_answer_collection\n"
     ]
    }
   ],
   "source": [
    "# Connect to ChromaDB and check collections\n",
    "try:\n",
    "    # Initialize ChromaDB client\n",
    "    db = chromadb.PersistentClient(path=vectorstore_path)\n",
    "    \n",
    "    # List all collections\n",
    "    collections = db.list_collections()\n",
    "    print(f\"Total collections found: {len(collections)}\")\n",
    "    print(\"\\nCollections:\")\n",
    "    for i, collection in enumerate(collections):\n",
    "        print(f\"{i+1}. {collection.name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to ChromaDB: {e}\")\n",
    "    print(\"Please check if the vectorstore path is correct and ChromaDB is properly initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55eb8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä QUESTION ANSWER COLLECTION STATISTICS:\n",
      "Total questions in collection: 137\n",
      "\n",
      "üìù SAMPLE DOCUMENTS (first 3):\n",
      "\n",
      "--- Document 1 ---\n",
      "ID: AI_engineer-0\n",
      "Text: AI kh√°c bi·ªát v·ªõi l·∫≠p tr√¨nh truy·ªÅn th·ªëng nh∆∞ th·∫ø n√†o?\n",
      "Metadata: {'answer': 'Tr√≠ tu·ªá Nh√¢n t·∫°o (AI) l√† khi c√°c c·ªó m√°y, ƒë·∫∑c bi·ªát l√† m√°y t√≠nh, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ suy nghƒ© v√† h√†nh ƒë·ªông nh∆∞ con ng∆∞·ªùi. AI gi√∫p m√°y m√≥c h·ªçc h·ªèi t·ª´ th√¥ng tin, gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ v√† t·ª± c·∫£i thi·ªán. Nh·ªØng kh√°c bi·ªát ch√≠nh: L·∫≠p tr√¨nh truy·ªÅn th·ªëng m√£ h√≥a r√µ r√†ng c√°c quy t·∫Øc, c√≤n AI h·ªçc c√°c m·∫´u t·ª´ d·ªØ li·ªáu; AI c√≥ th·ªÉ th√≠ch nghi v√† c·∫£i thi·ªán theo th·ªùi gian; v√† AI x·ª≠ l√Ω c√°c v·∫•n ƒë·ªÅ phi c·∫•u tr√∫c t·ªët h∆°n.', '_node_type': 'TextNode', 'document_id': 'None', 'question': 'AI kh√°c bi·ªát v·ªõi l·∫≠p tr√¨nh truy·ªÅn th·ªëng nh∆∞ th·∫ø n√†o?', 'doc_id': 'None', 'index': 0, 'source': 'AI_engineer', 'ref_doc_id': 'None', '_node_content': '{\"id_\": \"AI_engineer-0\", \"embedding\": null, \"metadata\": {\"source\": \"AI_engineer\", \"question\": \"AI kh\\\\u00e1c bi\\\\u1ec7t v\\\\u1edbi l\\\\u1eadp tr\\\\u00ecnh truy\\\\u1ec1n th\\\\u1ed1ng nh\\\\u01b0 th\\\\u1ebf n\\\\u00e0o?\", \"answer\": \"Tr\\\\u00ed tu\\\\u1ec7 Nh\\\\u00e2n t\\\\u1ea1o (AI) l\\\\u00e0 khi c\\\\u00e1c c\\\\u1ed7 m\\\\u00e1y, \\\\u0111\\\\u1eb7c bi\\\\u1ec7t l\\\\u00e0 m\\\\u00e1y t\\\\u00ednh, \\\\u0111\\\\u01b0\\\\u1ee3c thi\\\\u1ebft k\\\\u1ebf \\\\u0111\\\\u1ec3 suy ngh\\\\u0129 v\\\\u00e0 h\\\\u00e0nh \\\\u0111\\\\u1ed9ng nh\\\\u01b0 con ng\\\\u01b0\\\\u1eddi. AI gi\\\\u00fap m\\\\u00e1y m\\\\u00f3c h\\\\u1ecdc h\\\\u1ecfi t\\\\u1eeb th\\\\u00f4ng tin, gi\\\\u1ea3i quy\\\\u1ebft v\\\\u1ea5n \\\\u0111\\\\u1ec1 v\\\\u00e0 t\\\\u1ef1 c\\\\u1ea3i thi\\\\u1ec7n. Nh\\\\u1eefng kh\\\\u00e1c bi\\\\u1ec7t ch\\\\u00ednh: L\\\\u1eadp tr\\\\u00ecnh truy\\\\u1ec1n th\\\\u1ed1ng m\\\\u00e3 h\\\\u00f3a r\\\\u00f5 r\\\\u00e0ng c\\\\u00e1c quy t\\\\u1eafc, c\\\\u00f2n AI h\\\\u1ecdc c\\\\u00e1c m\\\\u1eabu t\\\\u1eeb d\\\\u1eef li\\\\u1ec7u; AI c\\\\u00f3 th\\\\u1ec3 th\\\\u00edch nghi v\\\\u00e0 c\\\\u1ea3i thi\\\\u1ec7n theo th\\\\u1eddi gian; v\\\\u00e0 AI x\\\\u1eed l\\\\u00fd c\\\\u00e1c v\\\\u1ea5n \\\\u0111\\\\u1ec1 phi c\\\\u1ea5u tr\\\\u00fac t\\\\u1ed1t h\\\\u01a1n.\", \"index\": 0}, \"excluded_embed_metadata_keys\": [], \"excluded_llm_metadata_keys\": [], \"relationships\": {}, \"metadata_template\": \"{key}: {value}\", \"metadata_separator\": \"\\\\n\", \"text\": \"\", \"mimetype\": \"text/plain\", \"start_char_idx\": null, \"end_char_idx\": null, \"metadata_seperator\": \"\\\\n\", \"text_template\": \"{metadata_str}\\\\n\\\\n{content}\", \"class_name\": \"TextNode\"}'}\n",
      "\n",
      "--- Document 2 ---\n",
      "ID: AI_engineer-1\n",
      "Text: C√°c nh√°nh ch√≠nh c·ªßa AI l√† g√¨?\n",
      "Metadata: {'_node_type': 'TextNode', 'document_id': 'None', '_node_content': '{\"id_\": \"AI_engineer-1\", \"embedding\": null, \"metadata\": {\"source\": \"AI_engineer\", \"question\": \"C\\\\u00e1c nh\\\\u00e1nh ch\\\\u00ednh c\\\\u1ee7a AI l\\\\u00e0 g\\\\u00ec?\", \"answer\": \"C\\\\u00e1c nh\\\\u00e1nh ch\\\\u00ednh c\\\\u1ee7a AI bao g\\\\u1ed3m: Machine Learning (ML) - thu\\\\u1eadt to\\\\u00e1n cho ph\\\\u00e9p m\\\\u00e1y h\\\\u1ecdc t\\\\u1eeb d\\\\u1eef li\\\\u1ec7u; Natural Language Processing (NLP) - t\\\\u01b0\\\\u01a1ng t\\\\u00e1c m\\\\u00e1y-ng\\\\u01b0\\\\u1eddi qua ng\\\\u00f4n ng\\\\u1eef t\\\\u1ef1 nhi\\\\u00ean; Robotics - thi\\\\u1ebft k\\\\u1ebf robot t\\\\u1ef1 \\\\u0111\\\\u1ed9ng; Computer Vision - m\\\\u00e1y hi\\\\u1ec3u v\\\\u00e0 quy\\\\u1ebft \\\\u0111\\\\u1ecbnh t\\\\u1eeb h\\\\u00ecnh \\\\u1ea3nh; Expert Systems - m\\\\u00f4 ph\\\\u1ecfng ki\\\\u1ebfn th\\\\u1ee9c chuy\\\\u00ean gia; Speech Recognition - chuy\\\\u1ec3n gi\\\\u1ecdng n\\\\u00f3i th\\\\u00e0nh v\\\\u0103n b\\\\u1ea3n; v\\\\u00e0 Planning & Scheduling - t\\\\u1ed1i \\\\u01b0u h\\\\u00f3a t\\\\u00e1c v\\\\u1ee5 v\\\\u00e0 t\\\\u00e0i nguy\\\\u00ean.\", \"index\": 1}, \"excluded_embed_metadata_keys\": [], \"excluded_llm_metadata_keys\": [], \"relationships\": {}, \"metadata_template\": \"{key}: {value}\", \"metadata_separator\": \"\\\\n\", \"text\": \"\", \"mimetype\": \"text/plain\", \"start_char_idx\": null, \"end_char_idx\": null, \"metadata_seperator\": \"\\\\n\", \"text_template\": \"{metadata_str}\\\\n\\\\n{content}\", \"class_name\": \"TextNode\"}', 'answer': 'C√°c nh√°nh ch√≠nh c·ªßa AI bao g·ªìm: Machine Learning (ML) - thu·∫≠t to√°n cho ph√©p m√°y h·ªçc t·ª´ d·ªØ li·ªáu; Natural Language Processing (NLP) - t∆∞∆°ng t√°c m√°y-ng∆∞·ªùi qua ng√¥n ng·ªØ t·ª± nhi√™n; Robotics - thi·∫øt k·∫ø robot t·ª± ƒë·ªông; Computer Vision - m√°y hi·ªÉu v√† quy·∫øt ƒë·ªãnh t·ª´ h√¨nh ·∫£nh; Expert Systems - m√¥ ph·ªèng ki·∫øn th·ª©c chuy√™n gia; Speech Recognition - chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n; v√† Planning & Scheduling - t·ªëi ∆∞u h√≥a t√°c v·ª• v√† t√†i nguy√™n.', 'index': 1, 'doc_id': 'None', 'ref_doc_id': 'None', 'question': 'C√°c nh√°nh ch√≠nh c·ªßa AI l√† g√¨?', 'source': 'AI_engineer'}\n",
      "\n",
      "--- Document 3 ---\n",
      "ID: AI_engineer-2\n",
      "Text: S·ª± kh√°c bi·ªát gi·ªØa AI m·∫°nh v√† AI y·∫øu l√† g√¨?\n",
      "Metadata: {'question': 'S·ª± kh√°c bi·ªát gi·ªØa AI m·∫°nh v√† AI y·∫øu l√† g√¨?', '_node_content': '{\"id_\": \"AI_engineer-2\", \"embedding\": null, \"metadata\": {\"source\": \"AI_engineer\", \"question\": \"S\\\\u1ef1 kh\\\\u00e1c bi\\\\u1ec7t gi\\\\u1eefa AI m\\\\u1ea1nh v\\\\u00e0 AI y\\\\u1ebfu l\\\\u00e0 g\\\\u00ec?\", \"answer\": \"AI m\\\\u1ea1nh (AGI) l\\\\u00e0 m\\\\u00e1y c\\\\u00f3 kh\\\\u1ea3 n\\\\u0103ng \\\\u00e1p d\\\\u1ee5ng tr\\\\u00ed th\\\\u00f4ng minh cho b\\\\u1ea5t k\\\\u1ef3 v\\\\u1ea5n \\\\u0111\\\\u1ec1 n\\\\u00e0o, nh\\\\u01b0 con ng\\\\u01b0\\\\u1eddi. AI y\\\\u1ebfu (Narrow AI) t\\\\u1eadp trung v\\\\u00e0o nhi\\\\u1ec7m v\\\\u1ee5 c\\\\u1ee5 th\\\\u1ec3 v\\\\u00e0 kh\\\\u00f4ng c\\\\u00f3 tr\\\\u00ed th\\\\u00f4ng minh t\\\\u1ed5ng qu\\\\u00e1t.\", \"index\": 2}, \"excluded_embed_metadata_keys\": [], \"excluded_llm_metadata_keys\": [], \"relationships\": {}, \"metadata_template\": \"{key}: {value}\", \"metadata_separator\": \"\\\\n\", \"text\": \"\", \"mimetype\": \"text/plain\", \"start_char_idx\": null, \"end_char_idx\": null, \"metadata_seperator\": \"\\\\n\", \"text_template\": \"{metadata_str}\\\\n\\\\n{content}\", \"class_name\": \"TextNode\"}', '_node_type': 'TextNode', 'document_id': 'None', 'doc_id': 'None', 'source': 'AI_engineer', 'index': 2, 'ref_doc_id': 'None', 'answer': 'AI m·∫°nh (AGI) l√† m√°y c√≥ kh·∫£ nƒÉng √°p d·ª•ng tr√≠ th√¥ng minh cho b·∫•t k·ª≥ v·∫•n ƒë·ªÅ n√†o, nh∆∞ con ng∆∞·ªùi. AI y·∫øu (Narrow AI) t·∫≠p trung v√†o nhi·ªám v·ª• c·ª• th·ªÉ v√† kh√¥ng c√≥ tr√≠ th√¥ng minh t·ªïng qu√°t.'}\n"
     ]
    }
   ],
   "source": [
    "# Check question_answer_collection specifically\n",
    "try:\n",
    "    # Get or create the question_answer_collection\n",
    "    question_collection = db.get_or_create_collection(\"question_answer_collection\")\n",
    "    \n",
    "    # Count total documents in the collection\n",
    "    total_count = question_collection.count()\n",
    "    print(f\"\\nüìä QUESTION ANSWER COLLECTION STATISTICS:\")\n",
    "    print(f\"Total questions in collection: {total_count}\")\n",
    "    \n",
    "    if total_count > 0:\n",
    "        # Get a sample of documents to see the structure\n",
    "        sample_docs = question_collection.get(limit=3)\n",
    "        \n",
    "        print(f\"\\nüìù SAMPLE DOCUMENTS (first 3):\")\n",
    "        for i, (doc_id, doc_text, metadata) in enumerate(zip(sample_docs['ids'], sample_docs['documents'], sample_docs['metadatas'])):\n",
    "            print(f\"\\n--- Document {i+1} ---\")\n",
    "            print(f\"ID: {doc_id}\")\n",
    "            print(f\"Text: {doc_text[:200]}...\" if len(doc_text) > 200 else f\"Text: {doc_text}\")\n",
    "            print(f\"Metadata: {metadata}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error accessing question_answer_collection: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c736b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà METADATA ANALYSIS:\n",
      "\n",
      "By Source:\n",
      "  AI_engineer: 50 questions\n",
      "  cloud_engineer: 87 questions\n",
      "\n",
      "By Index (first 10):\n",
      "  Index 0: 2 questions\n",
      "  Index 1: 2 questions\n",
      "  Index 2: 2 questions\n",
      "  Index 3: 2 questions\n",
      "  Index 4: 2 questions\n",
      "  Index 5: 2 questions\n",
      "  Index 6: 2 questions\n",
      "  Index 7: 2 questions\n",
      "  Index 8: 2 questions\n",
      "  Index 9: 2 questions\n",
      "\n",
      "üí° ANSWER ANALYSIS:\n",
      "Documents with answers: 137/137\n",
      "Answer coverage: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Analyze metadata to understand question distribution\n",
    "try:\n",
    "    if total_count > 0:\n",
    "        # Get all documents to analyze metadata\n",
    "        all_docs = question_collection.get()\n",
    "        \n",
    "        # Count by source\n",
    "        source_counts = {}\n",
    "        index_counts = {}\n",
    "        \n",
    "        for metadata in all_docs['metadatas']:\n",
    "            source = metadata.get('source', 'Unknown')\n",
    "            index = metadata.get('index', 'Unknown')\n",
    "            \n",
    "            source_counts[source] = source_counts.get(source, 0) + 1\n",
    "            index_counts[index] = index_counts.get(index, 0) + 1\n",
    "        \n",
    "        print(f\"\\nüìà METADATA ANALYSIS:\")\n",
    "        print(f\"\\nBy Source:\")\n",
    "        for source, count in sorted(source_counts.items()):\n",
    "            print(f\"  {source}: {count} questions\")\n",
    "        \n",
    "        print(f\"\\nBy Index (first 10):\")\n",
    "        for index, count in sorted(index_counts.items())[:10]:\n",
    "            print(f\"  Index {index}: {count} questions\")\n",
    "        \n",
    "        # Check if there are answers in metadata\n",
    "        answers_found = 0\n",
    "        for metadata in all_docs['metadatas']:\n",
    "            if metadata.get('answer'):\n",
    "                answers_found += 1\n",
    "        \n",
    "        print(f\"\\nüí° ANSWER ANALYSIS:\")\n",
    "        print(f\"Documents with answers: {answers_found}/{total_count}\")\n",
    "        print(f\"Answer coverage: {(answers_found/total_count)*100:.1f}%\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing metadata: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb67ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e70516",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7deb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae85307",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf87b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ebb1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c3e873e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç TESTING RETRIEVAL FUNCTIONALITY:\n",
      "\n",
      "Query: 'machine learning'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79.3M/79.3M [00:16<00:00, 4.98MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error testing retrieval: Collection expecting embedding with dimension of 1536, got 384\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval functionality\n",
    "try:\n",
    "    if total_count > 0:\n",
    "        print(f\"\\nüîç TESTING RETRIEVAL FUNCTIONALITY:\")\n",
    "        \n",
    "        # Test queries\n",
    "        test_queries = [\n",
    "            \"machine learning\",\n",
    "            \"python programming\", \n",
    "            \"data structures\",\n",
    "            \"algorithms\",\n",
    "            \"deep learning\"\n",
    "        ]\n",
    "        \n",
    "        for query in test_queries:\n",
    "            print(f\"\\nQuery: '{query}'\")\n",
    "            results = question_collection.query(\n",
    "                query_texts=[query],\n",
    "                n_results=3\n",
    "            )\n",
    "            \n",
    "            if results['documents'][0]:\n",
    "                print(f\"  Found {len(results['documents'][0])} results:\")\n",
    "                for i, (doc, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0])):\n",
    "                    print(f\"    {i+1}. {doc[:100]}... (Source: {metadata.get('source', 'Unknown')})\")\n",
    "            else:\n",
    "                print(f\"  No results found\")\n",
    "                \n",
    "except Exception as e:\n",
    "    print(f\"Error testing retrieval: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dddc51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã SUMMARY REPORT:\n",
      "==================================================\n",
      "Vectorstore Path: D:\\CODE\\dsc2025\\dsc2025API\\src\\chroma_db_master_program\n",
      "Path Exists: True\n",
      "Total Collections: 3\n",
      "Question Collection Count: 137\n",
      "==================================================\n",
      "\n",
      "‚úÖ Collection is ready for use!\n",
      "‚úÖ Total questions available: 137\n",
      "‚úÖ Answer coverage: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Summary report\n",
    "print(f\"\\nüìã SUMMARY REPORT:\")\n",
    "print(f\"=\" * 50)\n",
    "print(f\"Vectorstore Path: {vectorstore_path}\")\n",
    "print(f\"Path Exists: {os.path.exists(vectorstore_path)}\")\n",
    "print(f\"Total Collections: {len(collections) if 'collections' in locals() else 'N/A'}\")\n",
    "print(f\"Question Collection Count: {total_count if 'total_count' in locals() else 'N/A'}\")\n",
    "print(f\"=\" * 50)\n",
    "\n",
    "if 'total_count' in locals() and total_count > 0:\n",
    "    print(f\"\\n‚úÖ Collection is ready for use!\")\n",
    "    print(f\"‚úÖ Total questions available: {total_count}\")\n",
    "    if 'answers_found' in locals():\n",
    "        print(f\"‚úÖ Answer coverage: {(answers_found/total_count)*100:.1f}%\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Collection is empty or not accessible\")\n",
    "    print(f\"‚ùå Please check if questions have been properly embedded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d84216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç CHECKING 'question_collection' (the one mentioned in your log):\n",
      "Total questions in 'question_collection': 1768\n",
      "\n",
      "üìù SAMPLE DOCUMENTS from 'question_collection' (first 5):\n",
      "\n",
      "--- Document 1 ---\n",
      "ID: AI_engineer-0\n",
      "Text: AI kh√°c bi·ªát v·ªõi l·∫≠p tr√¨nh truy·ªÅn th·ªëng nh∆∞ th·∫ø n√†o?\n",
      "Metadata: {'source': 'AI_engineer', 'question': 'AI kh√°c bi·ªát v·ªõi l·∫≠p tr√¨nh truy·ªÅn th·ªëng nh∆∞ th·∫ø n√†o?', 'ref_doc_id': 'None', 'document_id': 'None', 'doc_id': 'None', 'answer': 'Tr√≠ tu·ªá Nh√¢n t·∫°o (AI) l√† khi c√°c c·ªó m√°y, ƒë·∫∑c bi·ªát l√† m√°y t√≠nh, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ suy nghƒ© v√† h√†nh ƒë·ªông nh∆∞ con ng∆∞·ªùi. AI gi√∫p m√°y m√≥c h·ªçc h·ªèi t·ª´ th√¥ng tin, gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ v√† t·ª± c·∫£i thi·ªán. Nh·ªØng kh√°c bi·ªát ch√≠nh: L·∫≠p tr√¨nh truy·ªÅn th·ªëng m√£ h√≥a r√µ r√†ng c√°c quy t·∫Øc, c√≤n AI h·ªçc c√°c m·∫´u t·ª´ d·ªØ li·ªáu; AI c√≥ th·ªÉ th√≠ch nghi v√† c·∫£i thi·ªán theo th·ªùi gian; v√† AI x·ª≠ l√Ω c√°c v·∫•n ƒë·ªÅ phi c·∫•u tr√∫c t·ªët h∆°n.', '_node_content': '{\"id_\": \"AI_engineer-0\", \"embedding\": null, \"metadata\": {\"source\": \"AI_engineer\", \"question\": \"AI kh\\\\u00e1c bi\\\\u1ec7t v\\\\u1edbi l\\\\u1eadp tr\\\\u00ecnh truy\\\\u1ec1n th\\\\u1ed1ng nh\\\\u01b0 th\\\\u1ebf n\\\\u00e0o?\", \"answer\": \"Tr\\\\u00ed tu\\\\u1ec7 Nh\\\\u00e2n t\\\\u1ea1o (AI) l\\\\u00e0 khi c\\\\u00e1c c\\\\u1ed7 m\\\\u00e1y, \\\\u0111\\\\u1eb7c bi\\\\u1ec7t l\\\\u00e0 m\\\\u00e1y t\\\\u00ednh, \\\\u0111\\\\u01b0\\\\u1ee3c thi\\\\u1ebft k\\\\u1ebf \\\\u0111\\\\u1ec3 suy ngh\\\\u0129 v\\\\u00e0 h\\\\u00e0nh \\\\u0111\\\\u1ed9ng nh\\\\u01b0 con ng\\\\u01b0\\\\u1eddi. AI gi\\\\u00fap m\\\\u00e1y m\\\\u00f3c h\\\\u1ecdc h\\\\u1ecfi t\\\\u1eeb th\\\\u00f4ng tin, gi\\\\u1ea3i quy\\\\u1ebft v\\\\u1ea5n \\\\u0111\\\\u1ec1 v\\\\u00e0 t\\\\u1ef1 c\\\\u1ea3i thi\\\\u1ec7n. Nh\\\\u1eefng kh\\\\u00e1c bi\\\\u1ec7t ch\\\\u00ednh: L\\\\u1eadp tr\\\\u00ecnh truy\\\\u1ec1n th\\\\u1ed1ng m\\\\u00e3 h\\\\u00f3a r\\\\u00f5 r\\\\u00e0ng c\\\\u00e1c quy t\\\\u1eafc, c\\\\u00f2n AI h\\\\u1ecdc c\\\\u00e1c m\\\\u1eabu t\\\\u1eeb d\\\\u1eef li\\\\u1ec7u; AI c\\\\u00f3 th\\\\u1ec3 th\\\\u00edch nghi v\\\\u00e0 c\\\\u1ea3i thi\\\\u1ec7n theo th\\\\u1eddi gian; v\\\\u00e0 AI x\\\\u1eed l\\\\u00fd c\\\\u00e1c v\\\\u1ea5n \\\\u0111\\\\u1ec1 phi c\\\\u1ea5u tr\\\\u00fac t\\\\u1ed1t h\\\\u01a1n.\", \"index\": 0}, \"excluded_embed_metadata_keys\": [], \"excluded_llm_metadata_keys\": [], \"relationships\": {}, \"metadata_template\": \"{key}: {value}\", \"metadata_separator\": \"\\\\n\", \"text\": \"\", \"mimetype\": \"text/plain\", \"start_char_idx\": null, \"end_char_idx\": null, \"metadata_seperator\": \"\\\\n\", \"text_template\": \"{metadata_str}\\\\n\\\\n{content}\", \"class_name\": \"TextNode\"}', 'index': 0, '_node_type': 'TextNode'}\n",
      "\n",
      "--- Document 2 ---\n",
      "ID: AI_engineer-1\n",
      "Text: C√°c nh√°nh ch√≠nh c·ªßa AI l√† g√¨?\n",
      "Metadata: {'ref_doc_id': 'None', 'index': 1, 'answer': 'C√°c nh√°nh ch√≠nh c·ªßa AI bao g·ªìm: Machine Learning (ML) - thu·∫≠t to√°n cho ph√©p m√°y h·ªçc t·ª´ d·ªØ li·ªáu; Natural Language Processing (NLP) - t∆∞∆°ng t√°c m√°y-ng∆∞·ªùi qua ng√¥n ng·ªØ t·ª± nhi√™n; Robotics - thi·∫øt k·∫ø robot t·ª± ƒë·ªông; Computer Vision - m√°y hi·ªÉu v√† quy·∫øt ƒë·ªãnh t·ª´ h√¨nh ·∫£nh; Expert Systems - m√¥ ph·ªèng ki·∫øn th·ª©c chuy√™n gia; Speech Recognition - chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n; v√† Planning & Scheduling - t·ªëi ∆∞u h√≥a t√°c v·ª• v√† t√†i nguy√™n.', '_node_type': 'TextNode', 'doc_id': 'None', 'question': 'C√°c nh√°nh ch√≠nh c·ªßa AI l√† g√¨?', 'source': 'AI_engineer', 'document_id': 'None', '_node_content': '{\"id_\": \"AI_engineer-1\", \"embedding\": null, \"metadata\": {\"source\": \"AI_engineer\", \"question\": \"C\\\\u00e1c nh\\\\u00e1nh ch\\\\u00ednh c\\\\u1ee7a AI l\\\\u00e0 g\\\\u00ec?\", \"answer\": \"C\\\\u00e1c nh\\\\u00e1nh ch\\\\u00ednh c\\\\u1ee7a AI bao g\\\\u1ed3m: Machine Learning (ML) - thu\\\\u1eadt to\\\\u00e1n cho ph\\\\u00e9p m\\\\u00e1y h\\\\u1ecdc t\\\\u1eeb d\\\\u1eef li\\\\u1ec7u; Natural Language Processing (NLP) - t\\\\u01b0\\\\u01a1ng t\\\\u00e1c m\\\\u00e1y-ng\\\\u01b0\\\\u1eddi qua ng\\\\u00f4n ng\\\\u1eef t\\\\u1ef1 nhi\\\\u00ean; Robotics - thi\\\\u1ebft k\\\\u1ebf robot t\\\\u1ef1 \\\\u0111\\\\u1ed9ng; Computer Vision - m\\\\u00e1y hi\\\\u1ec3u v\\\\u00e0 quy\\\\u1ebft \\\\u0111\\\\u1ecbnh t\\\\u1eeb h\\\\u00ecnh \\\\u1ea3nh; Expert Systems - m\\\\u00f4 ph\\\\u1ecfng ki\\\\u1ebfn th\\\\u1ee9c chuy\\\\u00ean gia; Speech Recognition - chuy\\\\u1ec3n gi\\\\u1ecdng n\\\\u00f3i th\\\\u00e0nh v\\\\u0103n b\\\\u1ea3n; v\\\\u00e0 Planning & Scheduling - t\\\\u1ed1i \\\\u01b0u h\\\\u00f3a t\\\\u00e1c v\\\\u1ee5 v\\\\u00e0 t\\\\u00e0i nguy\\\\u00ean.\", \"index\": 1}, \"excluded_embed_metadata_keys\": [], \"excluded_llm_metadata_keys\": [], \"relationships\": {}, \"metadata_template\": \"{key}: {value}\", \"metadata_separator\": \"\\\\n\", \"text\": \"\", \"mimetype\": \"text/plain\", \"start_char_idx\": null, \"end_char_idx\": null, \"metadata_seperator\": \"\\\\n\", \"text_template\": \"{metadata_str}\\\\n\\\\n{content}\", \"class_name\": \"TextNode\"}'}\n",
      "\n",
      "--- Document 3 ---\n",
      "ID: AI_engineer-2\n",
      "Text: S·ª± kh√°c bi·ªát gi·ªØa AI m·∫°nh v√† AI y·∫øu l√† g√¨?\n",
      "Metadata: {'doc_id': 'None', 'ref_doc_id': 'None', '_node_content': '{\"id_\": \"AI_engineer-2\", \"embedding\": null, \"metadata\": {\"source\": \"AI_engineer\", \"question\": \"S\\\\u1ef1 kh\\\\u00e1c bi\\\\u1ec7t gi\\\\u1eefa AI m\\\\u1ea1nh v\\\\u00e0 AI y\\\\u1ebfu l\\\\u00e0 g\\\\u00ec?\", \"answer\": \"AI m\\\\u1ea1nh (AGI) l\\\\u00e0 m\\\\u00e1y c\\\\u00f3 kh\\\\u1ea3 n\\\\u0103ng \\\\u00e1p d\\\\u1ee5ng tr\\\\u00ed th\\\\u00f4ng minh cho b\\\\u1ea5t k\\\\u1ef3 v\\\\u1ea5n \\\\u0111\\\\u1ec1 n\\\\u00e0o, nh\\\\u01b0 con ng\\\\u01b0\\\\u1eddi. AI y\\\\u1ebfu (Narrow AI) t\\\\u1eadp trung v\\\\u00e0o nhi\\\\u1ec7m v\\\\u1ee5 c\\\\u1ee5 th\\\\u1ec3 v\\\\u00e0 kh\\\\u00f4ng c\\\\u00f3 tr\\\\u00ed th\\\\u00f4ng minh t\\\\u1ed5ng qu\\\\u00e1t.\", \"index\": 2}, \"excluded_embed_metadata_keys\": [], \"excluded_llm_metadata_keys\": [], \"relationships\": {}, \"metadata_template\": \"{key}: {value}\", \"metadata_separator\": \"\\\\n\", \"text\": \"\", \"mimetype\": \"text/plain\", \"start_char_idx\": null, \"end_char_idx\": null, \"metadata_seperator\": \"\\\\n\", \"text_template\": \"{metadata_str}\\\\n\\\\n{content}\", \"class_name\": \"TextNode\"}', 'index': 2, 'question': 'S·ª± kh√°c bi·ªát gi·ªØa AI m·∫°nh v√† AI y·∫øu l√† g√¨?', 'source': 'AI_engineer', '_node_type': 'TextNode', 'document_id': 'None', 'answer': 'AI m·∫°nh (AGI) l√† m√°y c√≥ kh·∫£ nƒÉng √°p d·ª•ng tr√≠ th√¥ng minh cho b·∫•t k·ª≥ v·∫•n ƒë·ªÅ n√†o, nh∆∞ con ng∆∞·ªùi. AI y·∫øu (Narrow AI) t·∫≠p trung v√†o nhi·ªám v·ª• c·ª• th·ªÉ v√† kh√¥ng c√≥ tr√≠ th√¥ng minh t·ªïng qu√°t.'}\n",
      "\n",
      "--- Document 4 ---\n",
      "ID: AI_engineer-3\n",
      "Text: S·ª± kh√°c bi·ªát gi·ªØa AI bi·ªÉu t∆∞·ª£ng v√† AI k·∫øt n·ªëi l√† g√¨?\n",
      "Metadata: {'doc_id': 'None', '_node_content': '{\"id_\": \"AI_engineer-3\", \"embedding\": null, \"metadata\": {\"source\": \"AI_engineer\", \"question\": \"S\\\\u1ef1 kh\\\\u00e1c bi\\\\u1ec7t gi\\\\u1eefa AI bi\\\\u1ec3u t\\\\u01b0\\\\u1ee3ng v\\\\u00e0 AI k\\\\u1ebft n\\\\u1ed1i l\\\\u00e0 g\\\\u00ec?\", \"answer\": \"AI bi\\\\u1ec3u t\\\\u01b0\\\\u1ee3ng s\\\\u1eed d\\\\u1ee5ng quy t\\\\u1eafc v\\\\u00e0 logic r\\\\u00f5 r\\\\u00e0ng, bi\\\\u1ec3u di\\\\u1ec5n ki\\\\u1ebfn th\\\\u1ee9c b\\\\u1eb1ng k\\\\u00fd hi\\\\u1ec7u. AI k\\\\u1ebft n\\\\u1ed1i s\\\\u1eed d\\\\u1ee5ng m\\\\u1ea1ng n\\\\u01a1-ron m\\\\u00f4 ph\\\\u1ecfng c\\\\u1ea5u tr\\\\u00fac n\\\\u00e3o ng\\\\u01b0\\\\u1eddi v\\\\u00e0 h\\\\u1ecdc qua \\\\u0111i\\\\u1ec1u ch\\\\u1ec9nh tr\\\\u1ecdng s\\\\u1ed1.\", \"index\": 3}, \"excluded_embed_metadata_keys\": [], \"excluded_llm_metadata_keys\": [], \"relationships\": {}, \"metadata_template\": \"{key}: {value}\", \"metadata_separator\": \"\\\\n\", \"text\": \"\", \"mimetype\": \"text/plain\", \"start_char_idx\": null, \"end_char_idx\": null, \"metadata_seperator\": \"\\\\n\", \"text_template\": \"{metadata_str}\\\\n\\\\n{content}\", \"class_name\": \"TextNode\"}', 'question': 'S·ª± kh√°c bi·ªát gi·ªØa AI bi·ªÉu t∆∞·ª£ng v√† AI k·∫øt n·ªëi l√† g√¨?', 'index': 3, 'document_id': 'None', '_node_type': 'TextNode', 'answer': 'AI bi·ªÉu t∆∞·ª£ng s·ª≠ d·ª•ng quy t·∫Øc v√† logic r√µ r√†ng, bi·ªÉu di·ªÖn ki·∫øn th·ª©c b·∫±ng k√Ω hi·ªáu. AI k·∫øt n·ªëi s·ª≠ d·ª•ng m·∫°ng n∆°-ron m√¥ ph·ªèng c·∫•u tr√∫c n√£o ng∆∞·ªùi v√† h·ªçc qua ƒëi·ªÅu ch·ªânh tr·ªçng s·ªë.', 'source': 'AI_engineer', 'ref_doc_id': 'None'}\n",
      "\n",
      "--- Document 5 ---\n",
      "ID: AI_engineer-4\n",
      "Text: S·ª± kh√°c bi·ªát gi·ªØa m√¥ h√¨nh tham s·ªë v√† phi tham s·ªë l√† g√¨?\n",
      "Metadata: {'ref_doc_id': 'None', 'question': 'S·ª± kh√°c bi·ªát gi·ªØa m√¥ h√¨nh tham s·ªë v√† phi tham s·ªë l√† g√¨?', 'doc_id': 'None', 'source': 'AI_engineer', '_node_content': '{\"id_\": \"AI_engineer-4\", \"embedding\": null, \"metadata\": {\"source\": \"AI_engineer\", \"question\": \"S\\\\u1ef1 kh\\\\u00e1c bi\\\\u1ec7t gi\\\\u1eefa m\\\\u00f4 h\\\\u00ecnh tham s\\\\u1ed1 v\\\\u00e0 phi tham s\\\\u1ed1 l\\\\u00e0 g\\\\u00ec?\", \"answer\": \"M\\\\u00f4 h\\\\u00ecnh tham s\\\\u1ed1 c\\\\u00f3 s\\\\u1ed1 tham s\\\\u1ed1 c\\\\u1ed1 \\\\u0111\\\\u1ecbnh (v\\\\u00ed d\\\\u1ee5: h\\\\u1ed3i quy tuy\\\\u1ebfn t\\\\u00ednh) v\\\\u00e0 gi\\\\u1ea3 \\\\u0111\\\\u1ecbnh v\\\\u1ec1 ph\\\\u00e2n ph\\\\u1ed1i d\\\\u1eef li\\\\u1ec7u. M\\\\u00f4 h\\\\u00ecnh phi tham s\\\\u1ed1 c\\\\u00f3 s\\\\u1ed1 tham s\\\\u1ed1 linh ho\\\\u1ea1t (v\\\\u00ed d\\\\u1ee5: KNN, c\\\\u00e2y quy\\\\u1ebft \\\\u0111\\\\u1ecbnh) v\\\\u00e0 th\\\\u00edch \\\\u1ee9ng v\\\\u1edbi \\\\u0111\\\\u1ed9 ph\\\\u1ee9c t\\\\u1ea1p c\\\\u1ee7a d\\\\u1eef li\\\\u1ec7u.\", \"index\": 4}, \"excluded_embed_metadata_keys\": [], \"excluded_llm_metadata_keys\": [], \"relationships\": {}, \"metadata_template\": \"{key}: {value}\", \"metadata_separator\": \"\\\\n\", \"text\": \"\", \"mimetype\": \"text/plain\", \"start_char_idx\": null, \"end_char_idx\": null, \"metadata_seperator\": \"\\\\n\", \"text_template\": \"{metadata_str}\\\\n\\\\n{content}\", \"class_name\": \"TextNode\"}', 'document_id': 'None', '_node_type': 'TextNode', 'index': 4, 'answer': 'M√¥ h√¨nh tham s·ªë c√≥ s·ªë tham s·ªë c·ªë ƒë·ªãnh (v√≠ d·ª•: h·ªìi quy tuy·∫øn t√≠nh) v√† gi·∫£ ƒë·ªãnh v·ªÅ ph√¢n ph·ªëi d·ªØ li·ªáu. M√¥ h√¨nh phi tham s·ªë c√≥ s·ªë tham s·ªë linh ho·∫°t (v√≠ d·ª•: KNN, c√¢y quy·∫øt ƒë·ªãnh) v√† th√≠ch ·ª©ng v·ªõi ƒë·ªô ph·ª©c t·∫°p c·ªßa d·ªØ li·ªáu.'}\n"
     ]
    }
   ],
   "source": [
    "# Check specifically for question_collection (not question_answer_collection)\n",
    "try:\n",
    "    print(f\"\\nüîç CHECKING 'question_collection' (the one mentioned in your log):\")\n",
    "    \n",
    "    # Try to get question_collection\n",
    "    question_collection = db.get_or_create_collection(\"question_collection\")\n",
    "    \n",
    "    # Count total documents in the collection\n",
    "    total_count = question_collection.count()\n",
    "    print(f\"Total questions in 'question_collection': {total_count}\")\n",
    "    \n",
    "    if total_count > 0:\n",
    "        # Get a sample of documents to see the structure\n",
    "        sample_docs = question_collection.get(limit=5)\n",
    "        \n",
    "        print(f\"\\nüìù SAMPLE DOCUMENTS from 'question_collection' (first 5):\")\n",
    "        for i, (doc_id, doc_text, metadata) in enumerate(zip(sample_docs['ids'], sample_docs['documents'], sample_docs['metadatas'])):\n",
    "            print(f\"\\n--- Document {i+1} ---\")\n",
    "            print(f\"ID: {doc_id}\")\n",
    "            print(f\"Text: {doc_text[:200]}...\" if len(doc_text) > 200 else f\"Text: {doc_text}\")\n",
    "            print(f\"Metadata: {metadata}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error accessing 'question_collection': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d40cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä COMPARING BOTH COLLECTIONS:\n",
      "'question_answer_collection': 137 documents\n",
      "'question_collection': 1768 documents\n"
     ]
    }
   ],
   "source": [
    "# Compare both collections\n",
    "try:\n",
    "    print(f\"\\nüìä COMPARING BOTH COLLECTIONS:\")\n",
    "    \n",
    "    # Check question_answer_collection (used by chatbot_tools.py)\n",
    "    qa_collection = db.get_or_create_collection(\"question_answer_collection\")\n",
    "    qa_count = qa_collection.count()\n",
    "    \n",
    "    # Check question_collection (mentioned in your log)\n",
    "    q_collection = db.get_or_create_collection(\"question_collection\")\n",
    "    q_count = q_collection.count()\n",
    "    \n",
    "    print(f\"'question_answer_collection': {qa_count} documents\")\n",
    "    print(f\"'question_collection': {q_count} documents\")\n",
    "    \n",
    "    # Check if they are the same collection with different names\n",
    "    if qa_count == q_count and qa_count > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Both collections have the same count. They might be the same data.\")\n",
    "        \n",
    "        # Compare a few documents\n",
    "        qa_sample = qa_collection.get(limit=3)\n",
    "        q_sample = q_collection.get(limit=3)\n",
    "        \n",
    "        print(f\"\\nComparing first 3 documents:\")\n",
    "        for i in range(min(3, len(qa_sample['ids']))):\n",
    "            if qa_sample['ids'][i] == q_sample['ids'][i]:\n",
    "                print(f\"  Document {i+1}: Same ID ‚úÖ\")\n",
    "            else:\n",
    "                print(f\"  Document {i+1}: Different IDs ‚ùå\")\n",
    "                print(f\"    qa_collection: {qa_sample['ids'][i]}\")\n",
    "                print(f\"    q_collection: {q_sample['ids'][i]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error comparing collections: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba406bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the chatbot_tools.py configuration\n",
    "print(f\"\\nüîß CHECKING CHATBOT_TOOLS.PY CONFIGURATION:\")\n",
    "print(f\"Vectorstore path in chatbot_tools.py: {vectorstore_path}\")\n",
    "\n",
    "# Check what collection name is used in chatbot_tools.py\n",
    "try:\n",
    "    # This simulates what chatbot_tools.py does\n",
    "    db_test = chromadb.PersistentClient(path=vectorstore_path)\n",
    "    chroma_collection = db_test.get_or_create_collection(\"question_answer_collection\")\n",
    "    \n",
    "    print(f\"Collection name used by chatbot_tools.py: 'question_answer_collection'\")\n",
    "    print(f\"Count in this collection: {chroma_collection.count()}\")\n",
    "    \n",
    "    # Check if there are any documents with 'automation_engineer' in metadata\n",
    "    all_docs = chroma_collection.get()\n",
    "    automation_docs = []\n",
    "    \n",
    "    for i, metadata in enumerate(all_docs['metadatas']):\n",
    "        if metadata and 'source' in metadata:\n",
    "            if 'automation' in metadata['source'].lower() or 'engineer' in metadata['source'].lower():\n",
    "                automation_docs.append((i, metadata))\n",
    "    \n",
    "    print(f\"\\nDocuments with 'automation' or 'engineer' in source: {len(automation_docs)}\")\n",
    "    for i, (doc_idx, metadata) in enumerate(automation_docs[:5]):\n",
    "        print(f\"  {i+1}. Source: {metadata.get('source', 'Unknown')}\")\n",
    "        print(f\"     Text: {all_docs['documents'][doc_idx][:100]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error checking chatbot_tools configuration: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61db642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Copy data from question_collection to question_answer_collection\n",
    "print(f\"\\nüîß SOLUTION: COPYING DATA TO CORRECT COLLECTION\")\n",
    "\n",
    "try:\n",
    "    # Get source collection\n",
    "    source_collection = db.get_or_create_collection(\"question_collection\")\n",
    "    source_count = source_collection.count()\n",
    "    \n",
    "    # Get target collection (the one used by chatbot_tools.py)\n",
    "    target_collection = db.get_or_create_collection(\"question_answer_collection\")\n",
    "    target_count = target_collection.count()\n",
    "    \n",
    "    print(f\"Source collection ('question_collection'): {source_count} documents\")\n",
    "    print(f\"Target collection ('question_answer_collection'): {target_count} documents\")\n",
    "    \n",
    "    if source_count > 0:\n",
    "        # Get all documents from source\n",
    "        all_source_docs = source_collection.get()\n",
    "        \n",
    "        print(f\"\\nüìã Copying {source_count} documents...\")\n",
    "        \n",
    "        # Copy documents to target collection\n",
    "        for i, (doc_id, doc_text, metadata) in enumerate(zip(all_source_docs['ids'], all_source_docs['documents'], all_source_docs['metadatas'])):\n",
    "            try:\n",
    "                # Add to target collection\n",
    "                target_collection.add(\n",
    "                    documents=[doc_text],\n",
    "                    metadatas=[metadata],\n",
    "                    ids=[doc_id]\n",
    "                )\n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f\"  Copied {i + 1}/{source_count} documents...\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error copying document {doc_id}: {e}\")\n",
    "        \n",
    "        # Verify the copy\n",
    "        final_count = target_collection.count()\n",
    "        print(f\"\\n‚úÖ Copy completed!\")\n",
    "        print(f\"Final count in 'question_answer_collection': {final_count}\")\n",
    "        \n",
    "        # Test retrieval\n",
    "        print(f\"\\nüîç Testing retrieval...\")\n",
    "        test_results = target_collection.query(\n",
    "            query_texts=[\"automation engineer\"],\n",
    "            n_results=3\n",
    "        )\n",
    "        \n",
    "        if test_results['documents'][0]:\n",
    "            print(f\"Found {len(test_results['documents'][0])} results for 'automation engineer':\")\n",
    "            for i, doc in enumerate(test_results['documents'][0]):\n",
    "                print(f\"  {i+1}. {doc[:100]}...\")\n",
    "        else:\n",
    "            print(\"No results found for 'automation engineer'\")\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå Source collection is empty!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error copying data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a218526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVE SOLUTION: Check what collection name should be used\n",
    "print(f\"\\nüîß ALTERNATIVE SOLUTION: CHECKING COLLECTION NAMES\")\n",
    "\n",
    "try:\n",
    "    # List all collections to see what's available\n",
    "    all_collections = db.list_collections()\n",
    "    \n",
    "    print(f\"\\nüìã All available collections:\")\n",
    "    for i, collection in enumerate(all_collections):\n",
    "        count = collection.count()\n",
    "        print(f\"  {i+1}. '{collection.name}': {count} documents\")\n",
    "    \n",
    "    # Check if we should modify chatbot_tools.py instead\n",
    "    print(f\"\\nüí° RECOMMENDATION:\")\n",
    "    print(f\"If 'question_collection' has the data you want to use:\")\n",
    "    print(f\"1. Either copy data to 'question_answer_collection' (solution above)\")\n",
    "    print(f\"2. Or modify chatbot_tools.py line 49:\")\n",
    "    print(f\"   Change: chroma_collection = db.get_or_create_collection('question_answer_collection')\")\n",
    "    print(f\"   To:     chroma_collection = db.get_or_create_collection('question_collection')\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error checking collections: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d95af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda activate dsc2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26422f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no change     C:\\Users\\ADMIN\\miniconda3\\Scripts\\conda.exe\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\Scripts\\conda-env.exe\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\Scripts\\conda-script.py\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\Scripts\\conda-env-script.py\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\condabin\\conda.bat\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\Library\\bin\\conda.bat\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\condabin\\_conda_activate.bat\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\condabin\\rename_tmp.bat\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\condabin\\conda_auto_activate.bat\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\condabin\\conda_hook.bat\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\Scripts\\activate.bat\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\condabin\\activate.bat\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\condabin\\deactivate.bat\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\Scripts\\activate\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\Scripts\\deactivate\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\etc\\profile.d\\conda.sh\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\etc\\fish\\conf.d\\conda.fish\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\shell\\condabin\\Conda.psm1\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\shell\\condabin\\conda-hook.ps1\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\Lib\\site-packages\\xontrib\\conda.xsh\n",
      "no change     C:\\Users\\ADMIN\\miniconda3\\etc\\profile.d\\conda.csh\n",
      "no change     C:\\Users\\ADMIN\\Documents\\WindowsPowerShell\\profile.ps1\n",
      "no change     HKEY_CURRENT_USER\\Software\\Microsoft\\Command Processor\\AutoRun\n",
      "No action taken.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790de0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9244b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.core import Settings, Document, VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "import chromadb\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "embeding_model_name = os.getenv(\"EMBEDDING_MODEL_NAME\")\n",
    "embeding_model_deployment_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "embedding_api_key = os.getenv(\"AZURE_OPENAI_EMBEDDING_API_KEY\")\n",
    "embedding_endpoint = os.getenv(\"AZURE_OPENAI_EMBEDDING_ENDPOINT\")\n",
    "embedding_api_version = os.getenv(\"AZURE_OPENAI_EMBEDDING_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20dc933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "                model=embeding_model_name,\n",
    "                deployment_name=embeding_model_deployment_name,\n",
    "                api_key=embedding_api_key,\n",
    "                azure_endpoint=embedding_endpoint,\n",
    "                api_version=embedding_api_version,\n",
    "            )\n",
    "\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e27788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_15856\\1106691481.py:3: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  documents = SimpleDirectoryReader(\"D:\\CODE\\dsc2025\\dsc2025API\\src\\data\").load_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\BusinessAnalyst.csv with error: No columns to parse from file. Skipping...\n",
      "Failed to load file D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DataAnalyst.csv with error: No columns to parse from file. Skipping...\n",
      "Failed to load file D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DataScience_QA.csv with error: 'utf-8' codec can't decode byte 0xe2 in position 5: invalid continuation byte. Skipping...\n",
      "Failed to load file D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Game_QA.csv with error: Error tokenizing data. C error: Expected 3 fields in line 6, saw 4\n",
      ". Skipping...\n",
      "Failed to load file D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\QA_Tester.csv with error: No columns to parse from file. Skipping...\n",
      "Failed to load file D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Software_QA.csv with error: 'utf-8' codec can't decode byte 0x97 in position 20392: invalid start byte. Skipping...\n",
      "Failed to load file D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\SystemAdministrator.csv with error: No columns to parse from file. Skipping...\n",
      "Failed to load file D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\UIUXDesigner.csv with error: No columns to parse from file. Skipping...\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"D:\\CODE\\dsc2025\\dsc2025API\\src\\data\").load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c0b081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama_index.readers.database\n",
      "  Downloading llama_index_readers_database-0.5.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama_index.readers.database) (0.13.2)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (3.11.14)\n",
      "Requirement already satisfied: aiosqlite in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (2025.7.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.3.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (2.3.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (11.3.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (4.3.8)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (2.0.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (0.11.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (4.14.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.20.1)\n",
      "Requirement already satisfied: griffe in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.12.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (3.10)\n",
      "Requirement already satisfied: click in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (2025.7.34)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from anyio->httpx->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\quyno\\miniconda3\\envs\\chatbot_sdh\\lib\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama_index.readers.database) (3.0.2)\n",
      "Downloading llama_index_readers_database-0.5.0-py3-none-any.whl (6.4 kB)\n",
      "Installing collected packages: llama_index.readers.database\n",
      "Successfully installed llama_index.readers.database-0.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a887f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents_from_qa_data(df: pd.DataFrame, source_name: str) -> List[Document]:\n",
    "    \"\"\"Create Document objects from QA DataFrame\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # Create a combined text from question and answer\n",
    "        if 'Question' in row and 'Answer' in row:\n",
    "            # For DataScience QA format\n",
    "            question = row['Question']\n",
    "            answer = row['Answer']\n",
    "            combined_text = f\"Question: {question}\\nAnswer: {answer}\"\n",
    "            \n",
    "            # Create metadata\n",
    "            metadata = {\n",
    "                \"source\": source_name,\n",
    "                \"type\": \"qa_pair\",\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"index\": index\n",
    "            }\n",
    "        # Create Document object\n",
    "        doc = Document(\n",
    "            text=combined_text,\n",
    "            metadata=metadata\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    print(f\"Created {len(documents)} documents from {source_name}\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae85f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_vector_store(collection_name: str, documents: List[Document], db_path: str = \"./chroma_db_master_program\"):\n",
    "    \"\"\"Create a vector store with the given documents\"\"\"\n",
    "    try:\n",
    "        # Initialize ChromaDB\n",
    "        db = chromadb.PersistentClient(path=db_path)\n",
    "        chroma_collection = db.get_or_create_collection(collection_name)\n",
    "        \n",
    "        # Create vector store\n",
    "        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "        storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "        \n",
    "        # Create index\n",
    "        index = VectorStoreIndex(\n",
    "            documents, \n",
    "            storage_context=storage_context\n",
    "        )\n",
    "        \n",
    "        print(f\"Successfully created vector store for collection: {collection_name}\")\n",
    "        print(f\"Number of documents indexed: {len(documents)}\")\n",
    "        \n",
    "        return index, vector_store\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating vector store for {collection_name}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question\n",
      "Answer\n",
      "Created 158 documents from DataScience_QA\n",
      "Successfully created vector store for collection: datascience_qa_collection\n",
      "Number of documents indexed: 158\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('D:\\cv_review_module-main\\chatbot_sdh\\chatbot_mi\\src\\data\\DataScience_QA_vietnamese.csv', mode='r') as file:\n",
    "    DS_QA = pd.read_csv(file)\n",
    "    for row in DS_QA:\n",
    "        print(row)\n",
    "\n",
    "    if DS_QA is not None:\n",
    "        ds_documents = create_documents_from_qa_data(DS_QA, \"DataScience_QA\")\n",
    "        if ds_documents:\n",
    "            ds_index, ds_vector_store = create_vector_store(\n",
    "                \"datascience_qa_collection\", \n",
    "                ds_documents\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c519ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Number\n",
      "Question\n",
      "Answer\n",
      "Category\n",
      "Difficulty\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'create_documents_from_qa_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(row)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DS_QA \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     ds_documents = \u001b[43mcreate_documents_from_qa_data\u001b[49m(DS_QA, \u001b[33m\"\u001b[39m\u001b[33mSoftware_QA\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ds_documents:\n\u001b[32m      9\u001b[39m         ds_index, ds_vector_store = create_vector_store(\n\u001b[32m     10\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msoftware_qa_collection\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     11\u001b[39m             ds_documents\n\u001b[32m     12\u001b[39m         )\n",
      "\u001b[31mNameError\u001b[39m: name 'create_documents_from_qa_data' is not defined"
     ]
    }
   ],
   "source": [
    "with open('D:\\cv_review_module-main\\chatbot_sdh\\chatbot_mi\\src\\data\\Software_QA_vietnamese.csv', mode='r') as file:\n",
    "    DS_QA = pd.read_csv(file)\n",
    "    for row in DS_QA:\n",
    "        print(row)\n",
    "\n",
    "    if DS_QA is not None:\n",
    "        ds_documents = create_documents_from_qa_data(DS_QA, \"Software_QA\")\n",
    "        if ds_documents:\n",
    "            ds_index, ds_vector_store = create_vector_store(\n",
    "                \"software_qa_collection\", \n",
    "                ds_documents\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d3fd84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o Nodes thay v√¨ Documents\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "\n",
    "def create_nodes_from_qa_data(df: pd.DataFrame, source_name: str) -> List[TextNode]:\n",
    "    \"\"\"T·∫°o danh s√°ch TextNode t·ª´ DataFrame QA.\"\"\"\n",
    "    nodes: List[TextNode] = []\n",
    "    if \"Question\" not in df.columns and \"C√¢u h·ªèi\" in df.columns:\n",
    "        df = df.rename(columns={\"C√¢u h·ªèi\": \"Question\"})\n",
    "    if \"Answer\" not in df.columns and \"Tr·∫£ l·ªùi\" in df.columns:\n",
    "        df = df.rename(columns={\"Tr·∫£ l·ªùi\": \"Answer\"})\n",
    "\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if 'Question' not in row or 'Answer' not in row:\n",
    "            continue\n",
    "\n",
    "        question = row['Question']\n",
    "        answer = row['Answer']\n",
    "\n",
    "        text_parts = f\"{question}\"\n",
    "        metadata: Dict[str, Any] = {\n",
    "            \"source\": source_name,\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"index\": int(index),\n",
    "        }\n",
    "\n",
    "        node = TextNode(text=text_parts, metadata=metadata, id_=f\"{source_name}-{index}\")\n",
    "        nodes.append(node)\n",
    "\n",
    "    print(f\"Created {len(nodes)} nodes from {source_name}\")\n",
    "    return nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d5f6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L∆∞u Nodes v√†o Chroma th√¥ng qua VectorStoreIndex\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "import chromadb\n",
    "from typing import List\n",
    "# If you use TextNode, also ensure:\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "def store_nodes_in_chroma(nodes: List[TextNode], collection_name: str, db_path: str = \"./chroma_db_master_program\"):\n",
    "    db = chromadb.PersistentClient(path=db_path)\n",
    "    chroma_collection = db.get_or_create_collection(collection_name)\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "    # X√¢y index t·ª´ nodes (kh√¥ng ph·∫£i Documents)\n",
    "    index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "    print(f\"Stored {len(nodes)} nodes into collection: {collection_name}\")\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300c2262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chuy√™Ãân file xlsx sang csv\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d96f12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds_df = pd.read_csv('D:/CODE/dsc2025/dsc2025API/src/data/AIEngineer.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e93af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STT</th>\n",
       "      <th>C√¢u h·ªèi</th>\n",
       "      <th>Tr·∫£ l·ªùi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AI kh√°c bi·ªát v·ªõi l·∫≠p tr√¨nh truy·ªÅn th·ªëng nh∆∞ th...</td>\n",
       "      <td>Tr√≠ tu·ªá Nh√¢n t·∫°o (AI) l√† khi c√°c c·ªó m√°y, ƒë·∫∑c b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C√°c nh√°nh ch√≠nh c·ªßa AI l√† g√¨?</td>\n",
       "      <td>C√°c nh√°nh ch√≠nh c·ªßa AI bao g·ªìm: Machine Learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>S·ª± kh√°c bi·ªát gi·ªØa AI m·∫°nh v√† AI y·∫øu l√† g√¨?</td>\n",
       "      <td>AI m·∫°nh (AGI) l√† m√°y c√≥ kh·∫£ nƒÉng √°p d·ª•ng tr√≠ t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>S·ª± kh√°c bi·ªát gi·ªØa AI bi·ªÉu t∆∞·ª£ng v√† AI k·∫øt n·ªëi ...</td>\n",
       "      <td>AI bi·ªÉu t∆∞·ª£ng s·ª≠ d·ª•ng quy t·∫Øc v√† logic r√µ r√†ng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>S·ª± kh√°c bi·ªát gi·ªØa m√¥ h√¨nh tham s·ªë v√† phi tham ...</td>\n",
       "      <td>M√¥ h√¨nh tham s·ªë c√≥ s·ªë tham s·ªë c·ªë ƒë·ªãnh (v√≠ d·ª•: ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STT                                            C√¢u h·ªèi  \\\n",
       "0    1  AI kh√°c bi·ªát v·ªõi l·∫≠p tr√¨nh truy·ªÅn th·ªëng nh∆∞ th...   \n",
       "1    2                      C√°c nh√°nh ch√≠nh c·ªßa AI l√† g√¨?   \n",
       "2    3         S·ª± kh√°c bi·ªát gi·ªØa AI m·∫°nh v√† AI y·∫øu l√† g√¨?   \n",
       "3    4  S·ª± kh√°c bi·ªát gi·ªØa AI bi·ªÉu t∆∞·ª£ng v√† AI k·∫øt n·ªëi ...   \n",
       "4    5  S·ª± kh√°c bi·ªát gi·ªØa m√¥ h√¨nh tham s·ªë v√† phi tham ...   \n",
       "\n",
       "                                             Tr·∫£ l·ªùi  \n",
       "0  Tr√≠ tu·ªá Nh√¢n t·∫°o (AI) l√† khi c√°c c·ªó m√°y, ƒë·∫∑c b...  \n",
       "1  C√°c nh√°nh ch√≠nh c·ªßa AI bao g·ªìm: Machine Learni...  \n",
       "2  AI m·∫°nh (AGI) l√† m√°y c√≥ kh·∫£ nƒÉng √°p d·ª•ng tr√≠ t...  \n",
       "3  AI bi·ªÉu t∆∞·ª£ng s·ª≠ d·ª•ng quy t·∫Øc v√† logic r√µ r√†ng...  \n",
       "4  M√¥ h√¨nh tham s·ªë c√≥ s·ªë tham s·ªë c·ªë ƒë·ªãnh (v√≠ d·ª•: ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7efc110e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Question'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Question'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mds_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mQuestion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Question'"
     ]
    }
   ],
   "source": [
    "ds_df['Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742ce4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bdecff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CSV file reading...\n",
      "Failed to read D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DataScience_QA_vietnamese.csv: read_csv() got an unexpected keyword argument 'errors'\n",
      "Failed to read D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Software_QA_vietnamese.csv: read_csv() got an unexpected keyword argument 'errors'\n"
     ]
    }
   ],
   "source": [
    "# Fix encoding issues and update file paths\n",
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "def detect_and_read_csv(file_path):\n",
    "    \"\"\"Detect encoding and read CSV file\"\"\"\n",
    "    try:\n",
    "        # Try different encodings\n",
    "        encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1', 'utf-16']\n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding=encoding)\n",
    "                print(f\"Successfully read {file_path} with {encoding}: {len(df)} rows\")\n",
    "                return df\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        # If all encodings fail, try with error handling\n",
    "        df = pd.read_csv(file_path, encoding='utf-8', errors='ignore')\n",
    "        print(f\"Read {file_path} with error handling: {len(df)} rows\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test reading the problematic files\n",
    "print(\"Testing CSV file reading...\")\n",
    "ds_df = detect_and_read_csv(\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\DataScience_QA_vietnamese.csv\")\n",
    "sw_df = detect_and_read_csv(\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\Software_QA_vietnamese.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e010accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHUY·ªÇN ƒê·ªîI FILE EXCEL SANG CSV ===\n",
      "1. Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ file Excel trong th∆∞ m·ª•c data:\n",
      "üîç T√¨m th·∫•y 40 file Excel trong D:\\CODE\\dsc2025\\dsc2025API\\src\\data\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\AIEngineer.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\AIEngineer.csv\n",
      "   S·ªë d√≤ng: 50, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Automation.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Automation.csv\n",
      "   S·ªë d√≤ng: 19, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Backend_QA.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Backend_QA.csv\n",
      "   S·ªë d√≤ng: 86, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\blockchain.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\blockchain.csv\n",
      "   S·ªë d√≤ng: 50, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\BusinessAnalyst.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\BusinessAnalyst.csv\n",
      "   S·ªë d√≤ng: 31, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\CloudEngineer.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\CloudEngineer.csv\n",
      "   S·ªë d√≤ng: 87, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u H·ªèi', 'C√¢u Tr·∫£ L·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Cloude_computing.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Cloude_computing.csv\n",
      "   S·ªë d√≤ng: 39, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Cybersecurity.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Cybersecurity.csv\n",
      "   S·ªë d√≤ng: 46, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DataAnalyst.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DataAnalyst.csv\n",
      "   S·ªë d√≤ng: 50, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DataEngineer.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DataEngineer.csv\n",
      "   S·ªë d√≤ng: 100, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DataScience.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DataScience.csv\n",
      "   S·ªë d√≤ng: 154, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DB.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DB.csv\n",
      "   S·ªë d√≤ng: 60, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DBAdministrator.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DBAdministrator.csv\n",
      "   S·ªë d√≤ng: 150, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DevOps_QA.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\DevOps_QA.csv\n",
      "   S·ªë d√≤ng: 61, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi (theo ngu·ªìn)', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Fontend_QA.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Fontend_QA.csv\n",
      "   S·ªë d√≤ng: 100, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\FullStack_QA.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\FullStack_QA.csv\n",
      "   S·ªë d√≤ng: 207, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Game_QA.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Game_QA.csv\n",
      "   S·ªë d√≤ng: 30, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\genarativeAI.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\genarativeAI.csv\n",
      "   S·ªë d√≤ng: 49, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\IoT.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\IoT.csv\n",
      "   S·ªë d√≤ng: 34, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\ITProjectManager.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\ITProjectManager.csv\n",
      "   S·ªë d√≤ng: 46, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'Question', 'Answer']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\JavaSripts.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\JavaSripts.csv\n",
      "   S·ªë d√≤ng: 51, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\ML.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\ML.csv\n",
      "   S·ªë d√≤ng: 62, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u H·ªèi', 'C√¢u Tr·∫£ L·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\MobileApp_QA.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\MobileApp_QA.csv\n",
      "   S·ªë d√≤ng: 20, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'C√¢u tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\NetworkEngineer.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\NetworkEngineer.csv\n",
      "   S·ªë d√≤ng: 50, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\NLP.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\NLP.csv\n",
      "   S·ªë d√≤ng: 49, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\operate.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\operate.csv\n",
      "   S·ªë d√≤ng: 101, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\python.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\python.csv\n",
      "   S·ªë d√≤ng: 54, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\QA_Tester.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\QA_Tester.csv\n",
      "   S·ªë d√≤ng: 50, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\react.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\react.csv\n",
      "   S·ªë d√≤ng: 43, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\SoftSkill.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\SoftSkill.csv\n",
      "   S·ªë d√≤ng: 32, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Software (2).xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Software (2).csv\n",
      "   S·ªë d√≤ng: 51, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\softwaredev.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\softwaredev.csv\n",
      "   S·ªë d√≤ng: 25, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\softwaretesting.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\softwaretesting.csv\n",
      "   S·ªë d√≤ng: 51, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Spring.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\Spring.csv\n",
      "   S·ªë d√≤ng: 49, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\SQL.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\SQL.csv\n",
      "   S·ªë d√≤ng: 85, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\SystemAdministrator.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\SystemAdministrator.csv\n",
      "   S·ªë d√≤ng: 0, S·ªë c·ªôt: 0\n",
      "   C√°c c·ªôt: []\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\typescript.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\typescript.csv\n",
      "   S·ªë d√≤ng: 50, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\UIUXDesigner.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\UIUXDesigner.csv\n",
      "   S·ªë d√≤ng: 33, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\UserResearcher.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\UserResearcher.csv\n",
      "   S·ªë d√≤ng: 29, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u H·ªèi', 'C√¢u Tr·∫£ L·ªùi']\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\VR.xlsx -> D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\VR.csv\n",
      "   S·ªë d√≤ng: 30, S·ªë c·ªôt: 3\n",
      "   C√°c c·ªôt: ['STT', 'C√¢u h·ªèi', 'Tr·∫£ l·ªùi']\n",
      "\n",
      "‚úÖ Ho√†n th√†nh! ƒê√£ chuy·ªÉn ƒë·ªïi 40 file\n"
     ]
    }
   ],
   "source": [
    "# Code ƒë·ªÉ chuy·ªÉn ƒë·ªïi file Excel (.xlsx) sang CSV\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_xlsx_to_csv(xlsx_file_path, csv_file_path=None, sheet_name=0):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi file Excel sang CSV\n",
    "    \n",
    "    Args:\n",
    "        xlsx_file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel\n",
    "        csv_file_path (str, optional): ƒê∆∞·ªùng d·∫´n file CSV output. N·∫øu None, s·∫Ω t·ª± t·∫°o t√™n\n",
    "        sheet_name (str/int): T√™n sheet ho·∫∑c index sheet (m·∫∑c ƒë·ªãnh l√† 0)\n",
    "    \n",
    "    Returns:\n",
    "        str: ƒê∆∞·ªùng d·∫´n file CSV ƒë√£ t·∫°o\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ƒê·ªçc file Excel\n",
    "        df = pd.read_excel(xlsx_file_path, sheet_name=sheet_name)\n",
    "        \n",
    "        # T·∫°o t√™n file CSV n·∫øu kh√¥ng ƒë∆∞·ª£c cung c·∫•p\n",
    "        if csv_file_path is None:\n",
    "            xlsx_path = Path(xlsx_file_path)\n",
    "            csv_file_path = xlsx_path.parent / f\"{xlsx_path.stem}.csv\"\n",
    "        \n",
    "        # L∆∞u th√†nh CSV v·ªõi encoding UTF-8\n",
    "        df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: {xlsx_file_path} -> {csv_file_path}\")\n",
    "        print(f\"   S·ªë d√≤ng: {len(df)}, S·ªë c·ªôt: {len(df.columns)}\")\n",
    "        print(f\"   C√°c c·ªôt: {list(df.columns)}\")\n",
    "        \n",
    "        return str(csv_file_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi chuy·ªÉn ƒë·ªïi {xlsx_file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "#convert_xlsx_to_csv(str(\"D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\BusinessAnalyst.xlsx\"), str(\"D:\\CODE\\dsc2025\\dsc2025API\\src\\data\\BusinessAnalyst.csv\"))\n",
    "def convert_all_xlsx_in_directory(directory_path, output_directory=None):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ file Excel trong th∆∞ m·ª•c\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a file Excel\n",
    "        output_directory (str, optional): Th∆∞ m·ª•c output. N·∫øu None, s·∫Ω l∆∞u c√πng th∆∞ m·ª•c\n",
    "    \n",
    "    Returns:\n",
    "        list: Danh s√°ch c√°c file CSV ƒë√£ t·∫°o\n",
    "    \"\"\"\n",
    "    directory = Path(directory_path)\n",
    "    if output_directory:\n",
    "        output_dir = Path(output_directory)\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "    else:\n",
    "        output_dir = directory\n",
    "    \n",
    "    converted_files = []\n",
    "    xlsx_files = list(directory.glob(\"*.xlsx\"))\n",
    "    \n",
    "    print(f\"üîç T√¨m th·∫•y {len(xlsx_files)} file Excel trong {directory}\")\n",
    "    \n",
    "    for xlsx_file in xlsx_files:\n",
    "        csv_file = output_dir / f\"{xlsx_file.stem}.csv\"\n",
    "        result = convert_xlsx_to_csv(str(xlsx_file), str(csv_file))\n",
    "        if result:\n",
    "            converted_files.append(result)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Ho√†n th√†nh! ƒê√£ chuy·ªÉn ƒë·ªïi {len(converted_files)} file\")\n",
    "    return converted_files\n",
    "\n",
    "# V√≠ d·ª• s·ª≠ d·ª•ng\n",
    "print(\"=== CHUY·ªÇN ƒê·ªîI FILE EXCEL SANG CSV ===\")\n",
    "print(\"1. Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ file Excel trong th∆∞ m·ª•c data:\")\n",
    "converted_files = convert_all_xlsx_in_directory(\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a59c3133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== KI·ªÇM TRA T·∫§T C·∫¢ COLLECTIONS ===\n",
      "üìä T·ªïng s·ªë collections: 1\n",
      "==================================================\n",
      "üìÅ Collection: question_collection\n",
      "   - S·ªë documents: 0\n",
      "------------------------------\n",
      "\n",
      "üéØ T√≥m t·∫Øt:\n",
      "   - question_collection: 0 documents\n"
     ]
    }
   ],
   "source": [
    "# Ki·ªÉm tra t·∫•t c·∫£ collections trong ChromaDB\n",
    "print(\"\\n=== KI·ªÇM TRA T·∫§T C·∫¢ COLLECTIONS ===\")\n",
    "\n",
    "def check_all_collections(db_path: str = \"./chroma_db_master_program\"):\n",
    "    \"\"\"Ki·ªÉm tra t·∫•t c·∫£ collections trong ChromaDB\"\"\"\n",
    "    try:\n",
    "        db = chromadb.PersistentClient(path=db_path)\n",
    "        collections = db.list_collections()\n",
    "        \n",
    "        print(f\"üìä T·ªïng s·ªë collections: {len(collections)}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for collection in collections:\n",
    "            collection_name = collection.name\n",
    "            collection_info = collection.get()\n",
    "            \n",
    "            print(f\"üìÅ Collection: {collection_name}\")\n",
    "            print(f\"   - S·ªë documents: {len(collection_info['ids'])}\")\n",
    "            \n",
    "            if collection_info['metadatas']:\n",
    "                # L·∫•y metadata keys\n",
    "                metadata_keys = list(collection_info['metadatas'][0].keys())\n",
    "                print(f\"   - Metadata keys: {metadata_keys}\")\n",
    "                \n",
    "                # Hi·ªÉn th·ªã m·ªôt v√†i c√¢u h·ªèi m·∫´u\n",
    "                print(f\"   - C√¢u h·ªèi m·∫´u:\")\n",
    "                for i, metadata in enumerate(collection_info['metadatas'][:2]):\n",
    "                    question = metadata.get('question', 'N/A')\n",
    "                    if len(question) > 80:\n",
    "                        question = question[:80] + \"...\"\n",
    "                    print(f\"     {i+1}. {question}\")\n",
    "            \n",
    "            print(\"-\" * 30)\n",
    "        \n",
    "        return collections\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi ki·ªÉm tra collections: {e}\")\n",
    "        return None\n",
    "\n",
    "# Ki·ªÉm tra t·∫•t c·∫£ collections\n",
    "all_collections = check_all_collections()\n",
    "\n",
    "print(\"\\nüéØ T√≥m t·∫Øt:\")\n",
    "if all_collections:\n",
    "    for collection in all_collections:\n",
    "        collection_info = collection.get()\n",
    "        print(f\"   - {collection.name}: {len(collection_info['ids'])} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dacaa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 50 nodes from AI_engineer\n",
      "Stored 50 nodes into collection: question_collection\n"
     ]
    }
   ],
   "source": [
    "# Pipeline t·∫°o v√† l∆∞u nodes t·ª´ CSV\n",
    "# DataScience QA\n",
    "import pandas as pd\n",
    "# with open('D:\\cv_review_module-main\\chatbot_sdh\\chatbot_mi\\src\\data\\DataScience_QA_vietnamese.csv', mode='r') as file:\n",
    "#     ds_df = pd.read_csv(file)\n",
    "#     ds_nodes = create_nodes_from_qa_data(ds_df, \"DataScience_QA\")\n",
    "#     _ = store_nodes_in_chroma(ds_nodes, \"datascience\")\n",
    "\n",
    "# # Software QA\n",
    "with open(r'D:/CODE/dsc2025/dsc2025API/src/data/AIEngineer.csv', mode='r') as file:\n",
    "    sw_df = pd.read_csv(file)\n",
    "    sw_nodes = create_nodes_from_qa_data(sw_df, \"AI_engineer\")\n",
    "    _ = store_nodes_in_chroma(sw_nodes, \"question_collection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c317addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function ƒë·ªÉ th√™m c√¢u h·ªèi t·ª´ CSV v√†o QA_collection d∆∞·ªõi d·∫°ng TextNode\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "def add_questions_from_csv(\n",
    "    csv_file_path: str,\n",
    "    collection_name: str = \"QA_collection\",\n",
    "    source_name: Optional[str] = None,\n",
    "    db_path: str = \"./chroma_db_master_program\",\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    ƒê·ªçc CSV b·∫•t k·ª≥, chu·∫©n h√≥a c·ªôt h·ªèi/ƒë√°p, t·∫°o TextNode v√† l∆∞u v√†o collection.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path: ƒê∆∞·ªùng d·∫´n file CSV ngu·ªìn\n",
    "        collection_name: T√™n collection trong Chroma (m·∫∑c ƒë·ªãnh: QA_collection)\n",
    "        source_name: Nh√£n ngu·ªìn trong metadata (m·∫∑c ƒë·ªãnh: theo t√™n file)\n",
    "        db_path: ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ChromaDB\n",
    "    Returns:\n",
    "        True n·∫øu th√™m th√†nh c√¥ng, False n·∫øu l·ªói\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ƒê·ªçc CSV v·ªõi c√°c encoding ph·ªï bi·∫øn\n",
    "        encodings = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin-1\", \"iso-8859-1\"]\n",
    "        df = None\n",
    "        for enc in encodings:\n",
    "            try:\n",
    "                df = pd.read_csv(csv_file_path, encoding=enc)\n",
    "                break\n",
    "            except Exception:\n",
    "                continue\n",
    "        if df is None:\n",
    "            df = pd.read_csv(csv_file_path, encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "        # Chu·∫©n h√≥a c·ªôt v·ªÅ 'Question' v√† 'Answer'\n",
    "        rename_map_candidates = [\n",
    "            {\"C√¢u h·ªèi\": \"Question\", \"Tr·∫£ l·ªùi\": \"Answer\"},\n",
    "            {\"C√¢u h·ªèi (theo ngu·ªìn)\": \"Question\", \"Tr·∫£ l·ªùi\": \"Answer\"},\n",
    "            {\"C√¢u h·ªèi\": \"Question\", \"C√¢u tr·∫£ l·ªùi\": \"Answer\"},\n",
    "            {\"B·∫£ng C√¢u H·ªèi v√† Tr·∫£ L·ªùi Machine Learning\": \"Question\", \"Unnamed: 2\": \"Answer\"},\n",
    "            {\"Tr·∫£ l·ªùi (gi·ªØ nguy√™n)\": \"Answer\"},\n",
    "        ]\n",
    "        for rename_map in rename_map_candidates:\n",
    "            intersects = {k: v for k, v in rename_map.items() if k in df.columns}\n",
    "            if intersects:\n",
    "                df = df.rename(columns=intersects)\n",
    "\n",
    "        # Ch·ªâ gi·ªØ 2 c·ªôt c·∫ßn thi·∫øt\n",
    "        if \"Question\" in df.columns and \"Answer\" in df.columns:\n",
    "            df = df[[\"Question\", \"Answer\"]]\n",
    "        else:\n",
    "            print(\"‚ùå CSV c·∫ßn c√≥ c·ªôt 'Question' v√† 'Answer' (sau chu·∫©n h√≥a). C·ªôt hi·ªán c√≥:\", list(df.columns))\n",
    "            return False\n",
    "\n",
    "        # L·ªçc d√≤ng tr·ªëng\n",
    "        df = df.dropna(subset=[\"Question\", \"Answer\"]).reset_index(drop=True)\n",
    "        if df.empty:\n",
    "            print(\"‚ö†Ô∏è Kh√¥ng c√≥ b·∫£n ghi h·ª£p l·ªá sau khi l·ªçc.\")\n",
    "            return False\n",
    "\n",
    "        # X√°c ƒë·ªãnh ngu·ªìn\n",
    "        if not source_name:\n",
    "            source_name = Path(csv_file_path).stem\n",
    "\n",
    "        # T·∫°o nodes v√† l∆∞u\n",
    "        nodes = create_nodes_from_qa_data(df, source_name)\n",
    "        _ = store_nodes_in_chroma(nodes, collection_name, db_path)\n",
    "        print(f\"‚úÖ ƒê√£ th√™m {len(nodes)} nodes t·ª´ '{source_name}' v√†o collection '{collection_name}'.\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi th√™m d·ªØ li·ªáu t·ª´ CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "# V√≠ d·ª•: n·∫°p th√™m d·ªØ li·ªáu v√†o QA_collection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d99f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6602bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 19 nodes from automation_engineer\n",
      "Stored 19 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 19 nodes t·ª´ 'automation_engineer' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\Automation.csv\", \"question_collection\", \"automation_engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4741b3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 50 nodes from blockchain\n",
      "Stored 50 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 50 nodes t·ª´ 'blockchain' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\blockchain.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "281e43e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 87 nodes from CloudEngineer\n",
      "Stored 87 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 87 nodes t·ª´ 'CloudEngineer' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\CloudEngineer.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5662d7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 46 nodes from Cybersecurity\n",
      "Stored 46 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 46 nodes t·ª´ 'Cybersecurity' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\Cybersecurity.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05cc0d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 100 nodes from DataEngineer\n",
      "Stored 100 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 100 nodes t·ª´ 'DataEngineer' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\DataEngineer.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d9c4efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 150 nodes from DBAdministrator\n",
      "Stored 150 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 150 nodes t·ª´ 'DBAdministrator' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\DBAdministrator.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "788d34ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç T√¨m th·∫•y 42 file CSV trong folder data\n",
      "============================================================\n",
      "\n",
      "üìÑ [ 1/42] ƒêang x·ª≠ l√Ω: AIEngineer.csv\n",
      "Created 50 nodes from AIEngineer\n",
      "Stored 50 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 50 nodes t·ª´ 'AIEngineer' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: AIEngineer.csv\n",
      "\n",
      "üìÑ [ 2/42] ƒêang x·ª≠ l√Ω: Automation.csv\n",
      "Created 19 nodes from Automation\n",
      "Stored 19 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 19 nodes t·ª´ 'Automation' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: Automation.csv\n",
      "\n",
      "üìÑ [ 3/42] ƒêang x·ª≠ l√Ω: Backend_QA.csv\n",
      "Created 86 nodes from Backend_QA\n",
      "Stored 86 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 86 nodes t·ª´ 'Backend_QA' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: Backend_QA.csv\n",
      "\n",
      "üìÑ [ 4/42] ƒêang x·ª≠ l√Ω: BusinessAnalyst.csv\n",
      "Created 31 nodes from BusinessAnalyst\n",
      "Stored 31 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 31 nodes t·ª´ 'BusinessAnalyst' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: BusinessAnalyst.csv\n",
      "\n",
      "üìÑ [ 5/42] ƒêang x·ª≠ l√Ω: CloudEngineer.csv\n",
      "‚ùå CSV c·∫ßn c√≥ c·ªôt 'Question' v√† 'Answer' (sau chu·∫©n h√≥a). C·ªôt hi·ªán c√≥: ['STT', 'C√¢u H·ªèi', 'C√¢u Tr·∫£ L·ªùi']\n",
      "‚ùå Th·∫•t b·∫°i: CloudEngineer.csv\n",
      "\n",
      "üìÑ [ 6/42] ƒêang x·ª≠ l√Ω: Cloude_computing.csv\n",
      "Created 39 nodes from Cloude_computing\n",
      "Stored 39 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 39 nodes t·ª´ 'Cloude_computing' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: Cloude_computing.csv\n",
      "\n",
      "üìÑ [ 7/42] ƒêang x·ª≠ l√Ω: Cybersecurity.csv\n",
      "Created 46 nodes from Cybersecurity\n",
      "Stored 46 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 46 nodes t·ª´ 'Cybersecurity' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: Cybersecurity.csv\n",
      "\n",
      "üìÑ [ 8/42] ƒêang x·ª≠ l√Ω: DBAdministrator.csv\n",
      "Created 150 nodes from DBAdministrator\n",
      "Stored 150 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 150 nodes t·ª´ 'DBAdministrator' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: DBAdministrator.csv\n",
      "\n",
      "üìÑ [ 9/42] ƒêang x·ª≠ l√Ω: DataAnalyst.csv\n",
      "Created 50 nodes from DataAnalyst\n",
      "Stored 50 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 50 nodes t·ª´ 'DataAnalyst' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: DataAnalyst.csv\n",
      "\n",
      "üìÑ [10/42] ƒêang x·ª≠ l√Ω: DataBase.csv\n",
      "Created 60 nodes from DataBase\n",
      "Stored 60 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 60 nodes t·ª´ 'DataBase' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: DataBase.csv\n",
      "\n",
      "üìÑ [11/42] ƒêang x·ª≠ l√Ω: DataEngineer.csv\n",
      "Created 100 nodes from DataEngineer\n",
      "Stored 100 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 100 nodes t·ª´ 'DataEngineer' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: DataEngineer.csv\n",
      "\n",
      "üìÑ [12/42] ƒêang x·ª≠ l√Ω: DataScience.csv\n",
      "Created 154 nodes from DataScience\n",
      "Stored 154 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 154 nodes t·ª´ 'DataScience' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: DataScience.csv\n",
      "\n",
      "üìÑ [13/42] ƒêang x·ª≠ l√Ω: DevOps_QA.csv\n",
      "Created 61 nodes from DevOps_QA\n",
      "Stored 61 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 61 nodes t·ª´ 'DevOps_QA' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: DevOps_QA.csv\n",
      "\n",
      "üìÑ [14/42] ƒêang x·ª≠ l√Ω: Fontend_QA.csv\n",
      "Created 100 nodes from Fontend_QA\n",
      "Stored 100 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 100 nodes t·ª´ 'Fontend_QA' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: Fontend_QA.csv\n",
      "\n",
      "üìÑ [15/42] ƒêang x·ª≠ l√Ω: FullStack_QA.csv\n",
      "Created 199 nodes from FullStack_QA\n",
      "Stored 199 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 199 nodes t·ª´ 'FullStack_QA' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: FullStack_QA.csv\n",
      "\n",
      "üìÑ [16/42] ƒêang x·ª≠ l√Ω: Game_QA.csv\n",
      "‚ùå CSV c·∫ßn c√≥ c·ªôt 'Question' v√† 'Answer' (sau chu·∫©n h√≥a). C·ªôt hi·ªán c√≥: ['D∆∞·ªõi ƒë√¢y l√† b·∫£ng t·ªïng h·ª£p c√°c c√¢u h·ªèi ph·ªèng v·∫•n v√† c√¢u tr·∫£ l·ªùi m·∫´u cho v·ªã tr√≠ Nh√† ph√°t tri·ªÉn Game, d·ª±a tr√™n c√°c ngu·ªìn b·∫°n ƒë√£ cung c·∫•p:', 'Unnamed: 1']\n",
      "‚ùå Th·∫•t b·∫°i: Game_QA.csv\n",
      "\n",
      "üìÑ [17/42] ƒêang x·ª≠ l√Ω: ITProjectManager.csv\n",
      "Created 46 nodes from ITProjectManager\n",
      "Stored 46 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 46 nodes t·ª´ 'ITProjectManager' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: ITProjectManager.csv\n",
      "\n",
      "üìÑ [18/42] ƒêang x·ª≠ l√Ω: IoT.csv\n",
      "Created 34 nodes from IoT\n",
      "Stored 34 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 34 nodes t·ª´ 'IoT' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: IoT.csv\n",
      "\n",
      "üìÑ [19/42] ƒêang x·ª≠ l√Ω: JavaSripts.csv\n",
      "Created 51 nodes from JavaSripts\n",
      "Stored 51 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 51 nodes t·ª´ 'JavaSripts' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: JavaSripts.csv\n",
      "\n",
      "üìÑ [20/42] ƒêang x·ª≠ l√Ω: MachineLearning.csv\n",
      "‚ùå CSV c·∫ßn c√≥ c·ªôt 'Question' v√† 'Answer' (sau chu·∫©n h√≥a). C·ªôt hi·ªán c√≥: ['STT', 'C√¢u H·ªèi', 'C√¢u Tr·∫£ L·ªùi']\n",
      "‚ùå Th·∫•t b·∫°i: MachineLearning.csv\n",
      "\n",
      "üìÑ [21/42] ƒêang x·ª≠ l√Ω: MobileApp_QA.csv\n",
      "Created 20 nodes from MobileApp_QA\n",
      "Stored 20 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 20 nodes t·ª´ 'MobileApp_QA' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: MobileApp_QA.csv\n",
      "\n",
      "üìÑ [22/42] ƒêang x·ª≠ l√Ω: NLP.csv\n",
      "Created 49 nodes from NLP\n",
      "Stored 49 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 49 nodes t·ª´ 'NLP' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: NLP.csv\n",
      "\n",
      "üìÑ [23/42] ƒêang x·ª≠ l√Ω: NetworkEngineer.csv\n",
      "Created 49 nodes from NetworkEngineer\n",
      "Stored 49 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 49 nodes t·ª´ 'NetworkEngineer' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: NetworkEngineer.csv\n",
      "\n",
      "üìÑ [24/42] ƒêang x·ª≠ l√Ω: QA_Tester.csv\n",
      "Created 50 nodes from QA_Tester\n",
      "Stored 50 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 50 nodes t·ª´ 'QA_Tester' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: QA_Tester.csv\n",
      "\n",
      "üìÑ [25/42] ƒêang x·ª≠ l√Ω: SQL.csv\n",
      "Created 85 nodes from SQL\n",
      "Stored 85 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 85 nodes t·ª´ 'SQL' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: SQL.csv\n",
      "\n",
      "üìÑ [26/42] ƒêang x·ª≠ l√Ω: SoftSkill.csv\n",
      "Created 32 nodes from SoftSkill\n",
      "Stored 32 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 32 nodes t·ª´ 'SoftSkill' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: SoftSkill.csv\n",
      "\n",
      "üìÑ [27/42] ƒêang x·ª≠ l√Ω: SoftwareEngineer.csv\n",
      "Created 51 nodes from SoftwareEngineer\n",
      "Stored 51 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 51 nodes t·ª´ 'SoftwareEngineer' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: SoftwareEngineer.csv\n",
      "\n",
      "üìÑ [28/42] ƒêang x·ª≠ l√Ω: Spring.csv\n",
      "Created 49 nodes from Spring\n",
      "Stored 49 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 49 nodes t·ª´ 'Spring' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: Spring.csv\n",
      "\n",
      "üìÑ [29/42] ƒêang x·ª≠ l√Ω: UIUXDesigner.csv\n",
      "Created 33 nodes from UIUXDesigner\n",
      "Stored 33 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 33 nodes t·ª´ 'UIUXDesigner' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: UIUXDesigner.csv\n",
      "\n",
      "üìÑ [30/42] ƒêang x·ª≠ l√Ω: UserResearcher.csv\n",
      "‚ùå CSV c·∫ßn c√≥ c·ªôt 'Question' v√† 'Answer' (sau chu·∫©n h√≥a). C·ªôt hi·ªán c√≥: ['STT', 'C√¢u H·ªèi', 'C√¢u Tr·∫£ L·ªùi']\n",
      "‚ùå Th·∫•t b·∫°i: UserResearcher.csv\n",
      "\n",
      "üìÑ [31/42] ƒêang x·ª≠ l√Ω: VRVA.csv\n",
      "Created 30 nodes from VRVA\n",
      "Stored 30 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 30 nodes t·ª´ 'VRVA' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: VRVA.csv\n",
      "\n",
      "üìÑ [32/42] ƒêang x·ª≠ l√Ω: api_testing.csv\n",
      "Created 50 nodes from api_testing\n",
      "Stored 50 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 50 nodes t·ª´ 'api_testing' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: api_testing.csv\n",
      "\n",
      "üìÑ [33/42] ƒêang x·ª≠ l√Ω: blockchain.csv\n",
      "Created 50 nodes from blockchain\n",
      "Stored 50 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 50 nodes t·ª´ 'blockchain' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: blockchain.csv\n",
      "\n",
      "üìÑ [34/42] ƒêang x·ª≠ l√Ω: deep_learning.csv\n",
      "Created 55 nodes from deep_learning\n",
      "Stored 55 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 55 nodes t·ª´ 'deep_learning' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: deep_learning.csv\n",
      "\n",
      "üìÑ [35/42] ƒêang x·ª≠ l√Ω: genarativeAI.csv\n",
      "Created 49 nodes from genarativeAI\n",
      "Stored 49 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 49 nodes t·ª´ 'genarativeAI' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: genarativeAI.csv\n",
      "\n",
      "üìÑ [36/42] ƒêang x·ª≠ l√Ω: java.csv\n",
      "Created 192 nodes from java\n",
      "Stored 192 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 192 nodes t·ª´ 'java' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: java.csv\n",
      "\n",
      "üìÑ [37/42] ƒêang x·ª≠ l√Ω: operatingSystem.csv\n",
      "Created 101 nodes from operatingSystem\n",
      "Stored 101 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 101 nodes t·ª´ 'operatingSystem' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: operatingSystem.csv\n",
      "\n",
      "üìÑ [38/42] ƒêang x·ª≠ l√Ω: python.csv\n",
      "Created 54 nodes from python\n",
      "Stored 54 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 54 nodes t·ª´ 'python' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: python.csv\n",
      "\n",
      "üìÑ [39/42] ƒêang x·ª≠ l√Ω: react.csv\n",
      "Created 43 nodes from react\n",
      "Stored 43 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 43 nodes t·ª´ 'react' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: react.csv\n",
      "\n",
      "üìÑ [40/42] ƒêang x·ª≠ l√Ω: softwaredev.csv\n",
      "Created 25 nodes from softwaredev\n",
      "Stored 25 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 25 nodes t·ª´ 'softwaredev' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: softwaredev.csv\n",
      "\n",
      "üìÑ [41/42] ƒêang x·ª≠ l√Ω: softwaretesting.csv\n",
      "Created 51 nodes from softwaretesting\n",
      "Stored 51 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 51 nodes t·ª´ 'softwaretesting' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: softwaretesting.csv\n",
      "\n",
      "üìÑ [42/42] ƒêang x·ª≠ l√Ω: typescript.csv\n",
      "Created 50 nodes from typescript\n",
      "Stored 50 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 50 nodes t·ª´ 'typescript' v√†o collection 'question_collection'.\n",
      "‚úÖ Th√†nh c√¥ng: typescript.csv\n",
      "\n",
      "============================================================\n",
      "üìä T·ªîNG K·∫æT:\n",
      "‚úÖ Th√†nh c√¥ng: 38 files\n",
      "‚ùå Th·∫•t b·∫°i: 4 files\n",
      "üìÅ T·ªïng s·ªë files: 42\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2703cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç KI·ªÇM TRA K·∫æT QU·∫¢ CU·ªêI C√ôNG\n",
      "==================================================\n",
      "üìä T·ªïng s·ªë c√¢u h·ªèi trong collection: 2561\n",
      "\n",
      "üìà Ph√¢n b·ªë theo ngu·ªìn d·ªØ li·ªáu:\n",
      "----------------------------------------\n",
      "  AIEngineer               :   50 c√¢u h·ªèi\n",
      "  Automation               :   19 c√¢u h·ªèi\n",
      "  Backend_QA               :   86 c√¢u h·ªèi\n",
      "  BusinessAnalyst          :   31 c√¢u h·ªèi\n",
      "  CloudEngineer            :   87 c√¢u h·ªèi\n",
      "  Cloude_computing         :   39 c√¢u h·ªèi\n",
      "  Cybersecurity            :   46 c√¢u h·ªèi\n",
      "  DBAdministrator          :  150 c√¢u h·ªèi\n",
      "  DataAnalyst              :   50 c√¢u h·ªèi\n",
      "  DataBase                 :   60 c√¢u h·ªèi\n",
      "  DataEngineer             :  100 c√¢u h·ªèi\n",
      "  DataScience              :  154 c√¢u h·ªèi\n",
      "  DevOps_QA                :   61 c√¢u h·ªèi\n",
      "  Fontend_QA               :  100 c√¢u h·ªèi\n",
      "  FullStack_QA             :  199 c√¢u h·ªèi\n",
      "  Game_QA                  :   30 c√¢u h·ªèi\n",
      "  ITProjectManager         :   46 c√¢u h·ªèi\n",
      "  IoT                      :   34 c√¢u h·ªèi\n",
      "  JavaSripts               :   51 c√¢u h·ªèi\n",
      "  MobileApp_QA             :   20 c√¢u h·ªèi\n",
      "  NLP                      :   49 c√¢u h·ªèi\n",
      "  NetworkEngineer          :   49 c√¢u h·ªèi\n",
      "  QA_Tester                :   50 c√¢u h·ªèi\n",
      "  SQL                      :   85 c√¢u h·ªèi\n",
      "  SoftSkill                :   32 c√¢u h·ªèi\n",
      "  SoftwareEngineer         :   51 c√¢u h·ªèi\n",
      "  Spring                   :   49 c√¢u h·ªèi\n",
      "  UIUXDesigner             :   33 c√¢u h·ªèi\n",
      "  VRVA                     :   30 c√¢u h·ªèi\n",
      "  api_testing              :   50 c√¢u h·ªèi\n",
      "  blockchain               :   50 c√¢u h·ªèi\n",
      "  deep_learning            :   55 c√¢u h·ªèi\n",
      "  genarativeAI             :   49 c√¢u h·ªèi\n",
      "  java                     :  192 c√¢u h·ªèi\n",
      "  operatingSystem          :  101 c√¢u h·ªèi\n",
      "  python                   :   54 c√¢u h·ªèi\n",
      "  react                    :   43 c√¢u h·ªèi\n",
      "  softwaredev              :   25 c√¢u h·ªèi\n",
      "  softwaretesting          :   51 c√¢u h·ªèi\n",
      "  typescript               :   50 c√¢u h·ªèi\n",
      "\n",
      "üìù C√¢u h·ªèi m·∫´u (5 c√¢u ƒë·∫ßu ti√™n):\n",
      "----------------------------------------\n",
      "1. [AIEngineer] AI kh√°c bi·ªát v·ªõi l·∫≠p tr√¨nh truy·ªÅn th·ªëng nh∆∞ th·∫ø n√†o?...\n",
      "2. [AIEngineer] C√°c nh√°nh ch√≠nh c·ªßa AI l√† g√¨?...\n",
      "3. [AIEngineer] S·ª± kh√°c bi·ªát gi·ªØa AI m·∫°nh v√† AI y·∫øu l√† g√¨?...\n",
      "4. [AIEngineer] S·ª± kh√°c bi·ªát gi·ªØa AI bi·ªÉu t∆∞·ª£ng v√† AI k·∫øt n·ªëi l√† g√¨?...\n",
      "5. [AIEngineer] S·ª± kh√°c bi·ªát gi·ªØa m√¥ h√¨nh tham s·ªë v√† phi tham s·ªë l√† g√¨?...\n",
      "\n",
      "‚úÖ Collection ƒë√£ s·∫µn s√†ng v·ªõi 2561 c√¢u h·ªèi t·ª´ 40 ngu·ªìn d·ªØ li·ªáu!\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d15cdd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 29 nodes from UserResearcher\n",
      "Stored 29 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 29 nodes t·ª´ 'UserResearcher' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\UserResearcher.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c8fc1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 100 nodes from frontend\n",
      "Stored 100 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 100 nodes t·ª´ 'frontend' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\Fontend_QA.csv\", \"question_collection\", \"frontend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77ddf7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 199 nodes from fullstack\n",
      "Stored 199 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 199 nodes t·ª´ 'fullstack' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\FullStack_QA.csv\", \"question_collection\", \"fullstack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "076e7d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 34 nodes from IoT\n",
      "Stored 34 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 34 nodes t·ª´ 'IoT' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\IoT.csv\", \"question_collection\", \"IoT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83f6a0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 29 nodes from ITProjectManager\n",
      "Stored 29 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 29 nodes t·ª´ 'ITProjectManager' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\ITProjectManager.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4e955ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 62 nodes from machinglearning\n",
      "Stored 62 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 62 nodes t·ª´ 'machinglearning' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\ML.csv\", \"question_collection\", \"machinglearning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5105f990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 20 nodes from MobileApp\n",
      "Stored 20 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 20 nodes t·ª´ 'MobileApp' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\MobileApp_QA.csv\", \"question_collection\", \"MobileApp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d38b728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 49 nodes from NetworkEngineer\n",
      "Stored 49 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 49 nodes t·ª´ 'NetworkEngineer' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\NetworkEngineer.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c32cff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 29 nodes from UserResearcher\n",
      "Stored 29 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 29 nodes t·ª´ 'UserResearcher' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\UserResearcher.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4db1b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 30 nodes from VRAREngineer\n",
      "Stored 30 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 30 nodes t·ª´ 'VRAREngineer' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\VR.csv\", \"question_collection\", \"VRAREngineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88668aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 86 nodes from backend\n",
      "Stored 86 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 86 nodes t·ª´ 'backend' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\Backend_QA.csv\", \"question_collection\", \"backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb092309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 31 nodes from BusinessAnalyst\n",
      "Stored 31 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 31 nodes t·ª´ 'BusinessAnalyst' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\BusinessAnalyst.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e31a5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 50 nodes from DataAnalyst\n",
      "Stored 50 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 50 nodes t·ª´ 'DataAnalyst' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\DataAnalyst.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a10772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 154 nodes from DataScience\n",
      "Stored 154 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 154 nodes t·ª´ 'DataScience' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\DataScience.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f54ec45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 46 nodes from ITProjectManager\n",
      "Stored 46 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 46 nodes t·ª´ 'ITProjectManager' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\ITProjectManager.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de276583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 50 nodes from QA_tester\n",
      "Stored 50 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 50 nodes t·ª´ 'QA_tester' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\QA_tester.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ec4e7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 32 nodes from SoftSkill\n",
      "Stored 32 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 32 nodes t·ª´ 'SoftSkill' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\SoftSkill.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f47b544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 200 nodes from SoftwareEngineer\n",
      "Stored 200 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 200 nodes t·ª´ 'SoftwareEngineer' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\Software.csv\", \"question_collection\", \"SoftwareEngineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87b252b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 33 nodes from UIUXDesigner\n",
      "Stored 33 nodes into collection: question_collection\n",
      "‚úÖ ƒê√£ th√™m 33 nodes t·ª´ 'UIUXDesigner' v√†o collection 'question_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_questions_from_csv(r\"D:\\\\CODE\\\\dsc2025\\\\dsc2025API\\\\src\\\\data\\\\UIUXDesigner.csv\", \"question_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac295e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå L·ªói khi x√≥a collection 'datascience_qa_collection': Database error: error returned from database: (code: 1) no such table: tenants\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd728f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
