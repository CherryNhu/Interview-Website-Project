STT,Câu hỏi,Trả lời
1,AI khác biệt với lập trình truyền thống như thế nào?,"Trí tuệ Nhân tạo (AI) là khi các cỗ máy, đặc biệt là máy tính, được thiết kế để suy nghĩ và hành động như con người. AI giúp máy móc học hỏi từ thông tin, giải quyết vấn đề và tự cải thiện. Những khác biệt chính: Lập trình truyền thống mã hóa rõ ràng các quy tắc, còn AI học các mẫu từ dữ liệu; AI có thể thích nghi và cải thiện theo thời gian; và AI xử lý các vấn đề phi cấu trúc tốt hơn."
2,Các nhánh chính của AI là gì?,Các nhánh chính của AI bao gồm: Machine Learning (ML) - thuật toán cho phép máy học từ dữ liệu; Natural Language Processing (NLP) - tương tác máy-người qua ngôn ngữ tự nhiên; Robotics - thiết kế robot tự động; Computer Vision - máy hiểu và quyết định từ hình ảnh; Expert Systems - mô phỏng kiến thức chuyên gia; Speech Recognition - chuyển giọng nói thành văn bản; và Planning & Scheduling - tối ưu hóa tác vụ và tài nguyên.
3,Sự khác biệt giữa AI mạnh và AI yếu là gì?,"AI mạnh (AGI) là máy có khả năng áp dụng trí thông minh cho bất kỳ vấn đề nào, như con người. AI yếu (Narrow AI) tập trung vào nhiệm vụ cụ thể và không có trí thông minh tổng quát."
4,Sự khác biệt giữa AI biểu tượng và AI kết nối là gì?,"AI biểu tượng sử dụng quy tắc và logic rõ ràng, biểu diễn kiến thức bằng ký hiệu. AI kết nối sử dụng mạng nơ-ron mô phỏng cấu trúc não người và học qua điều chỉnh trọng số."
5,Sự khác biệt giữa mô hình tham số và phi tham số là gì?,"Mô hình tham số có số tham số cố định (ví dụ: hồi quy tuyến tính) và giả định về phân phối dữ liệu. Mô hình phi tham số có số tham số linh hoạt (ví dụ: KNN, cây quyết định) và thích ứng với độ phức tạp của dữ liệu."
6,Các bước triển khai mô hình ML vào sản xuất là gì?,"Các bước triển khai mô hình ML vào sản xuất bao gồm: tiền xử lý dữ liệu và huấn luyện mô hình; đánh giá hiệu suất mô hình; đóng gói mô hình (Docker); triển khai trên cloud (AWS, GCP, Azure); và giám sát và duy trì mô hình."
7,Các kỹ thuật tránh overfitting là gì?,"Các kỹ thuật tránh overfitting bao gồm: Regularization - thêm hình phạt cho hệ số lớn (L1, L2); Early Stopping - dừng huấn luyện trước khi quá phức tạp; Dropout - ngẫu nhiên bỏ các đơn vị trong mạng nơ-ron; và Data Augmentation - tăng dữ liệu bằng biến đổi."
8,Khác biệt giữa batch learning và online learning?,Batch Learning huấn luyện toàn bộ dataset cùng lúc và cập nhật ít thường xuyên. Online Learning huấn luyện từng mẫu khi dữ liệu đến và phù hợp cho hệ thống thời gian thực.
9,Khác biệt giữa eigenvalues và eigenvectors?,Eigenvalues là đại lượng vô hướng cho biết mức độ thay đổi tỉ lệ của eigenvector. Eigenvectors là vectơ chỉ thay đổi theo yếu tố vô hướng khi biến đổi tuyến tính.
10,Các nền tảng phát triển AI khác nhau là gì?,Các nền tảng phát triển AI bao gồm: TensorFlow - Framework ML của Google; PyTorch - Thư viện ML của Facebook; Keras - API mạng nơ-ron cấp cao; Azure AI - Dịch vụ AI của Microsoft; Google Cloud AI - Dịch vụ AI của Google; IBM Watson - Công cụ AI của IBM; và Amazon SageMaker - Dịch vụ ML của AWS.
11,Giải thích kiến trúc Mô hình Diffusion,"Mô hình Diffusion là mô hình tạo sinh chuyển đổi phân phối nhiễu thành dữ liệu phức tạp. Nó bao gồm Forward Process (dần thêm nhiễu vào dữ liệu) và Reverse Process (học đảo ngược quá trình, loại bỏ nhiễu để tạo mẫu mới). Ưu điểm là tạo ra kết quả ấn tượng trong tạo hình ảnh và âm thanh."
12,Các tác nhân khác nhau trong AI?,Các tác nhân trong AI bao gồm: 1. Simple Reflex Agents - hành động dựa trên nhận thức hiện tại; 2. Model-Based Reflex Agents - duy trì trạng thái nội bộ; 3. Goal-Based Agents - hành động để đạt mục tiêu cụ thể; 4. Utility-Based Agents - chọn hành động dựa trên hàm tiện ích; 5. Learning Agents - học từ kinh nghiệm và điều chỉnh hành vi.
13,Tác nhân hợp lý và tính hợp lý là gì?,"Một Rational Agent hành động để đạt kết quả tốt nhất có thể dựa trên thông tin hiện tại. Rationality là phẩm chất dựa trên lý trí và logic, nhằm tối đa hóa thước đo hiệu suất."
14,Cơ chế điều phối trong môi trường đa tác nhân?,Các cơ chế điều phối bao gồm: Communication Protocols - trao đổi thông tin và đàm phán; Distributed Planning - lập kế hoạch có tính đến người khác; Market-Based Mechanisms - đấu giá nhiệm vụ/tài nguyên; và Coordination Algorithms - tối ưu hiệu suất tập thể.
15,Tác nhân hình thành vấn đề như thế nào?,Tác nhân hình thành vấn đề bằng cách xác định các thành phần: Initial State (điều kiện ban đầu); Actions (tập hành động có thể); Transition Model (kết quả của mỗi hành động); Goal State (kết quả mong muốn); và Path Cost (chi phí cho mỗi đường đi).
16,Các loại thuật toán tìm kiếm trong giải quyết vấn đề?,"Các loại thuật toán tìm kiếm được chia thành: Uninformed Search (không có thông tin bổ sung) bao gồm Breadth-First Search (BFS), Depth-First Search (DFS), Uniform Cost Search; và Informed Search (sử dụng heuristic) bao gồm A* Search, Greedy Best-First Search, Beam Search."
17,Khác biệt giữa tìm kiếm có thông tin và không thông tin?,"Uninformed Search là tìm kiếm mù quáng, không có kiến thức chuyên biệt. Informed Search sử dụng heuristic để hướng dẫn tìm kiếm hiệu quả hơn."
18,Vai trò của heuristics trong tìm kiếm cục bộ?,"Heuristics cung cấp cách ước tính mức độ gần với trạng thái mục tiêu, giúp thuật toán đưa ra quyết định sáng suốt hơn về trạng thái nào khám phá tiếp theo."
19,Logic mờ (Fuzzy Logic) là gì?,"Logic mờ là logic xử lý các giá trị ""ở giữa"" thay vì chỉ ""đúng/sai"", rất hữu ích cho thông tin không chắc chắn (ví dụ: ""ấm"" hay ""lạnh"")."
20,Lý thuyết trò chơi (Game Theory) là gì?,"Lý thuyết trò chơi là nghiên cứu tương tác chiến lược giữa những người ra quyết định hợp lý, cung cấp công cụ phân tích tình huống cạnh tranh và hợp tác."
21,Học tăng cường và các thành phần chính?,Học tăng cường (RL) là khi tác nhân học ra quyết định để tối đa hóa phần thưởng tích lũy. Các thành phần chính gồm: Agent (người học); Environment (hệ thống bên ngoài); State (tình hình hiện tại); Actions (nước đi có thể); Reward (tín hiệu phản hồi); và Policy (chiến lược hành vi).
22,Chiến lược tối ưu hóa mô hình AI cho sản xuất?,"Các chiến lược tối ưu hóa bao gồm: Model Quantization - giảm độ chính xác trọng số; Pruning - loại bỏ phần ít quan trọng; Hardware Acceleration - sử dụng GPU, TPU; Model Caching - lưu kết quả thường dùng; và Monitoring & Retraining - giám sát và huấn luyện lại."
23,Các thành phần của hệ thống chuyên gia?,Các thành phần của hệ thống chuyên gia gồm: Knowledge Base (kho tri thức chuyên biệt); Inference Engine (áp dụng quy tắc logic); User Interface (giao diện người dùng); Explanation Facility (giải thích quá trình suy luận); và Knowledge Acquisition (thu thập và cập nhật tri thức).
24,Embeddings trong học máy là gì?,"Embeddings là biểu diễn đối tượng (từ, hình ảnh) trong không gian vector liên tục, nắm bắt mối quan hệ ngữ nghĩa và sự tương đồng."
25,Tối đa hóa phần thưởng trong RL hoạt động ra sao?,"Tác nhân sử dụng policy để chọn hành động dựa trên phần thưởng dự kiến, và cập nhật value function và policy bằng các thuật toán như Q-learning hoặc SARSA."
26,Gradient descent trong học máy?,Gradient descent là thuật toán tối ưu giảm thiểu loss function bằng cách điều chỉnh tham số theo hướng ngược gradient. Các biến thể gồm: Batch (toàn bộ dataset); SGD (từng mẫu); và Mini-batch (lô nhỏ).
27,Khác biệt giữa thuật toán di truyền và tìm kiếm cục bộ?,"Thuật toán di truyền dựa trên quần thể, sử dụng chọn lọc, lai ghép và đột biến. Tìm kiếm cục bộ khám phá từ giải pháp này sang lân cận và tập trung vào một giải pháp."
28,Cực tiểu cục bộ và ảnh hưởng đến tìm kiếm cục bộ?,Cực tiểu cục bộ là giải pháp tốt hơn lân cận nhưng không phải tối ưu toàn cục. Thuật toán tìm kiếm cục bộ có thể bị mắc kẹt tại đây; kỹ thuật như simulated annealing có thể giúp thoát.
29,Khác biệt giữa logic mệnh đề và logic bậc nhất?,"Logic mệnh đề xử lý mệnh đề đúng/sai, sử dụng các toán tử AND, OR, NOT. Logic bậc nhất mở rộng với quantifiers và predicates, cho phép biểu diễn mối quan hệ đối tượng phức tạp hơn."
30,Đánh đổi exploration vs exploitation trong tìm kiếm cục bộ?,Exploration là thử các giải pháp mới. Exploitation là tinh chỉnh giải pháp hiện tại. Cần cân bằng để tránh mắc kẹt ở cực tiểu cục bộ mà không lãng phí tài nguyên.
31,Khác biệt giữa hill climbing và simulated annealing?,Hill Climbing chỉ di chuyển đến giải pháp tốt hơn và dễ mắc kẹt ở cực tiểu cục bộ. Simulated Annealing đôi khi chấp nhận giải pháp tệ hơn với xác suất giảm dần để thoát khỏi cực tiểu cục bộ.
32,Cơ sở tri thức quan trọng như thế nào?,"Cơ sở tri thức là nền tảng cho hệ thống chuyên gia và AI, chứa thông tin có cấu trúc về domain cụ thể, hỗ trợ ra quyết định và giải quyết vấn đề."
33,Kỹ thuật biểu diễn tri thức hỗ trợ hệ thống thông minh?,Các kỹ thuật biểu diễn tri thức hỗ trợ hệ thống thông minh gồm: Symbolic Representation - nắm bắt mối quan hệ phức tạp; Logical Reasoning - áp dụng quy tắc để suy ra tri thức mới; và Semantic Understanding - hiểu ý nghĩa thông tin theo ngữ cảnh.
34,Khác biệt RL model-free vs model-based?,"Model-Free RL học trực tiếp từ reward mà không xây dựng mô hình môi trường (ví dụ: Q-learning, SARSA). Model-Based RL xây dựng mô hình môi trường để dự đoán và lập kế hoạch (ví dụ: Dyna-Q, MCTS)."
35,AI tạo sinh và các kiến trúc phổ biến?,"AI tạo sinh tạo nội dung mới từ dữ liệu huấn luyện. Các kiến trúc phổ biến gồm: GANs (Generator vs Discriminator); VAEs (phương pháp xác suất); và Transformers (GPT-3, DALL-E)."
36,Khác biệt trò chơi zero-sum và non-zero-sum?,"Trong trò chơi zero-sum, tổng thắng/thua bằng 0, nghĩa là một người thắng thì người khác thua. Trong trò chơi non-zero-sum, cả hai người chơi có thể cùng thắng hoặc cùng thua."
37,Bài toán thỏa mãn ràng buộc (CSP)?,"Bài toán thỏa mãn ràng buộc (CSP) là bài toán với tập biến, domain giá trị và các ràng buộc. Mục tiêu là tìm cách gán giá trị thỏa mãn tất cả ràng buộc, thường dùng trong lập lịch và phân bổ tài nguyên."
38,Suy luận trong AI?,"Suy luận trong AI là quá trình rút ra kiến thức mới từ thông tin hiện có bằng lý luận logic, và là thành phần chính của hệ thống chuyên gia và ra quyết định."
39,Ưu nhược điểm forward vs backward chaining?,Forward Chaining hiệu quả để suy ra nhiều kết luận nhưng có thể không hiệu quả với không gian lớn. Backward Chaining hiệu quả cho mục tiêu cụ thể nhưng có thể chậm nếu có nhiều quy tắc.
40,Mạng Bayesian mô hình hóa mối quan hệ xác suất?,"Mạng Bayesian sử dụng đồ thị định hướng không chu trình (DAG) với các nút là biến ngẫu nhiên và các cạnh là phụ thuộc có điều kiện, cho phép biểu diễn và tính toán xác suất một cách hiệu quả."
41,Khác biệt Q-learning vs SARSA?,Q-learning là off-policy và sử dụng giá trị phần thưởng lớn nhất của trạng thái tiếp theo. SARSA là on-policy và sử dụng hành động thực tế sẽ được thực hiện trong trạng thái tiếp theo.
42,Alpha-beta pruning trong tìm kiếm đối kháng?,"Alpha-beta pruning là kỹ thuật tối ưu hóa cho thuật toán minimax bằng cách loại bỏ các nhánh không ảnh hưởng đến quyết định cuối cùng, từ đó giảm số lượng nút cần đánh giá."
43,Backtracking search trong CSPs?,"Backtracking search là thuật toán DFS xây dựng dần giải pháp và quay lui khi gặp vi phạm ràng buộc, cho phép khám phá có hệ thống các cách gán giá trị."
44,Vai trò minimax trong tìm kiếm đối kháng?,"Minimax tìm chiến lược tối ưu trong trò chơi hai người bằng cách giả định cả hai người chơi đều tối ưu, và đánh giá đệ quy cây trò chơi."
45,Thuật toán A* và chiến lược heuristic?,"Thuật toán A* tìm đường đi ngắn nhất bằng cách sử dụng hàm đánh giá f(n) = g(n) + h(n), cân bằng giữa chi phí thực tế đã đi (g(n)) và ước tính chi phí đến mục tiêu (h(n))."
46,MDP và liên quan đến RL?,"MDP (Markov Decision Process) là framework cho ra quyết định ngẫu nhiên với States, Actions, Transitions, Rewards và Policy. Học tăng cường (RL) giải quyết MDP để tìm policy tối ưu."
47,Hidden Markov Models (HMMs)?,Hidden Markov Models (HMMs) là mô hình xác suất với các trạng thái ẩn và các quan sát. Chúng được dùng trong nhận dạng giọng nói và NLP để mô hình hóa các chuỗi có mẫu ẩn.
48,Autoencoders trong deep learning?,"Autoencoders là mạng nơ-ron unsupervised với encoder (nén dữ liệu) và decoder (giải nén dữ liệu). Chúng được dùng cho giảm chiều dữ liệu, khử nhiễu và tạo sinh."
49,Kiến trúc GANs?,Kiến trúc GANs bao gồm Generator (tạo dữ liệu giả) và Discriminator (phân biệt dữ liệu thật/giả). Chúng cạnh tranh trong một trò chơi zero-sum cho đến khi Generator tạo ra dữ liệu không thể phân biệt được.
50,Kiến trúc Transformer?,"Kiến trúc Transformer sử dụng cơ chế self-attention thay cho RNN/CNN. Nó gồm encoder và decoder với multi-head attention, cho phép huấn luyện song song và đạt hiệu suất cao trong NLP."
